{
    "llama2": {
        "description": "Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.",
        "tags": [
            "latest",
            "text",
            "7b",
            "70b",
            "chat",
            "13b",
            "7b-text",
            "7b-chat",
            "13b-chat",
            "13b-text",
            "70b-chat",
            "70b-text",
            "7b-chat-q4_0",
            "7b-chat-q4_1",
            "7b-chat-q5_0",
            "7b-chat-q5_1",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K",
            "7b-chat-fp16",
            "7b-text-q4_0",
            "7b-text-q4_1",
            "7b-text-q5_0",
            "7b-text-q5_1",
            "7b-text-q8_0",
            "7b-text-q2_K",
            "7b-text-q3_K_S",
            "7b-text-q3_K_M",
            "7b-text-q3_K_L",
            "7b-text-q4_K_S",
            "7b-text-q4_K_M",
            "7b-text-q5_K_S",
            "7b-text-q5_K_M",
            "7b-text-q6_K",
            "7b-text-fp16",
            "13b-chat-q4_0",
            "13b-chat-q4_1",
            "13b-chat-q5_0",
            "13b-chat-q5_1",
            "13b-chat-q8_0",
            "13b-chat-q2_K",
            "13b-chat-q3_K_S",
            "13b-chat-q3_K_M",
            "13b-chat-q3_K_L",
            "13b-chat-q4_K_S",
            "13b-chat-q4_K_M",
            "13b-chat-q5_K_S",
            "13b-chat-q5_K_M",
            "13b-chat-q6_K",
            "13b-chat-fp16",
            "13b-text-q4_0",
            "13b-text-q4_1",
            "13b-text-q5_0",
            "13b-text-q5_1",
            "13b-text-q8_0",
            "13b-text-q2_K",
            "13b-text-q3_K_S",
            "13b-text-q3_K_M",
            "13b-text-q3_K_L",
            "13b-text-q4_K_S",
            "13b-text-q4_K_M",
            "13b-text-q5_K_S",
            "13b-text-q5_K_M",
            "13b-text-q6_K",
            "13b-text-fp16",
            "70b-chat-q4_0",
            "70b-chat-q4_1",
            "70b-chat-q5_0",
            "70b-chat-q5_1",
            "70b-chat-q8_0",
            "70b-chat-q2_K",
            "70b-chat-q3_K_S",
            "70b-chat-q3_K_M",
            "70b-chat-q3_K_L",
            "70b-chat-q4_K_S",
            "70b-chat-q4_K_M",
            "70b-chat-q5_K_S",
            "70b-chat-q5_K_M",
            "70b-chat-q6_K",
            "70b-chat-fp16",
            "70b-text-q4_0",
            "70b-text-q4_1",
            "70b-text-q5_0",
            "70b-text-q5_1",
            "70b-text-q8_0",
            "70b-text-q2_K",
            "70b-text-q3_K_S",
            "70b-text-q3_K_M",
            "70b-text-q3_K_L",
            "70b-text-q4_K_S",
            "70b-text-q4_K_M",
            "70b-text-q5_K_S",
            "70b-text-q5_K_M",
            "70b-text-q6_K",
            "70b-text-fp16"
        ]
    },
    "mistral": {
        "description": "The 7B model released by Mistral AI, updated to version 0.2.",
        "tags": [
            "latest",
            "instruct",
            "v0.2",
            "text",
            "7b",
            "v0.1",
            "7b-text",
            "7b-instruct",
            "7b-instruct-q4_0",
            "7b-instruct-q4_1",
            "7b-instruct-q5_0",
            "7b-instruct-q5_1",
            "7b-instruct-q8_0",
            "7b-instruct-q2_K",
            "7b-instruct-q3_K_S",
            "7b-instruct-q3_K_M",
            "7b-instruct-q3_K_L",
            "7b-instruct-q4_K_S",
            "7b-instruct-q4_K_M",
            "7b-instruct-q5_K_S",
            "7b-instruct-q5_K_M",
            "7b-instruct-q6_K",
            "7b-instruct-fp16",
            "7b-text-q4_0",
            "7b-text-q4_1",
            "7b-text-q5_0",
            "7b-text-q5_1",
            "7b-text-q8_0",
            "7b-text-q2_K",
            "7b-text-q3_K_S",
            "7b-text-q3_K_M",
            "7b-text-q3_K_L",
            "7b-text-q4_K_S",
            "7b-text-q4_K_M",
            "7b-text-q5_K_S",
            "7b-text-q5_K_M",
            "7b-text-q6_K",
            "7b-text-fp16",
            "7b-instruct-v0.2-q4_0",
            "7b-instruct-v0.2-q4_1",
            "7b-instruct-v0.2-q5_0",
            "7b-instruct-v0.2-q5_1",
            "7b-instruct-v0.2-q8_0",
            "7b-instruct-v0.2-q2_K",
            "7b-instruct-v0.2-q3_K_S",
            "7b-instruct-v0.2-q3_K_M",
            "7b-instruct-v0.2-q3_K_L",
            "7b-instruct-v0.2-q4_K_S",
            "7b-instruct-v0.2-q4_K_M",
            "7b-instruct-v0.2-q5_K_S",
            "7b-instruct-v0.2-q5_K_M",
            "7b-instruct-v0.2-q6_K",
            "7b-instruct-v0.2-fp16"
        ]
    },
    "codellama": {
        "description": "A large language model that can use text prompts to generate and discuss code.",
        "tags": [
            "latest",
            "instruct",
            "code",
            "34b",
            "7b",
            "70b",
            "python",
            "13b",
            "7b-instruct",
            "7b-python",
            "7b-code",
            "13b-python",
            "13b-code",
            "13b-instruct",
            "34b-instruct",
            "34b-code",
            "34b-python",
            "70b-python",
            "70b-instruct",
            "70b-code",
            "7b-code-q4_0",
            "7b-code-q4_1",
            "7b-code-q5_0",
            "7b-code-q5_1",
            "7b-code-q8_0",
            "7b-code-q2_K",
            "7b-code-q3_K_S",
            "7b-code-q3_K_M",
            "7b-code-q3_K_L",
            "7b-code-q4_K_S",
            "7b-code-q4_K_M",
            "7b-code-q5_K_S",
            "7b-code-q5_K_M",
            "7b-code-q6_K",
            "7b-code-fp16",
            "7b-instruct-q4_0",
            "7b-instruct-q4_1",
            "7b-instruct-q5_0",
            "7b-instruct-q5_1",
            "7b-instruct-q8_0",
            "7b-instruct-q2_K",
            "7b-instruct-q3_K_S",
            "7b-instruct-q3_K_M",
            "7b-instruct-q3_K_L",
            "7b-instruct-q4_K_S",
            "7b-instruct-q4_K_M",
            "7b-instruct-q5_K_S",
            "7b-instruct-q5_K_M",
            "7b-instruct-q6_K",
            "7b-instruct-fp16",
            "7b-python-q4_0",
            "7b-python-q4_1",
            "7b-python-q5_0",
            "7b-python-q5_1",
            "7b-python-q8_0",
            "7b-python-q2_K",
            "7b-python-q3_K_S",
            "7b-python-q3_K_M",
            "7b-python-q3_K_L",
            "7b-python-q4_K_S",
            "7b-python-q4_K_M",
            "7b-python-q5_K_S",
            "7b-python-q5_K_M",
            "7b-python-q6_K",
            "7b-python-fp16",
            "13b-code-q4_0",
            "13b-code-q4_1",
            "13b-code-q5_0",
            "13b-code-q5_1",
            "13b-code-q8_0",
            "13b-code-q2_K",
            "13b-code-q3_K_S",
            "13b-code-q3_K_M",
            "13b-code-q3_K_L",
            "13b-code-q4_K_S",
            "13b-code-q4_K_M",
            "13b-code-q5_K_S",
            "13b-code-q5_K_M",
            "13b-code-q6_K",
            "13b-code-fp16",
            "13b-instruct-q4_0",
            "13b-instruct-q4_1",
            "13b-instruct-q5_0",
            "13b-instruct-q5_1",
            "13b-instruct-q8_0",
            "13b-instruct-q2_K",
            "13b-instruct-q3_K_S",
            "13b-instruct-q3_K_M",
            "13b-instruct-q3_K_L",
            "13b-instruct-q4_K_S",
            "13b-instruct-q4_K_M",
            "13b-instruct-q5_K_S",
            "13b-instruct-q5_K_M",
            "13b-instruct-q6_K",
            "13b-instruct-fp16",
            "13b-python-q4_0",
            "13b-python-q4_1",
            "13b-python-q5_0",
            "13b-python-q5_1",
            "13b-python-q8_0",
            "13b-python-q2_K",
            "13b-python-q3_K_S",
            "13b-python-q3_K_M",
            "13b-python-q3_K_L",
            "13b-python-q4_K_S",
            "13b-python-q4_K_M",
            "13b-python-q5_K_S",
            "13b-python-q5_K_M",
            "13b-python-q6_K",
            "13b-python-fp16",
            "34b-code-q4_0",
            "34b-code-q4_1",
            "34b-code-q5_0",
            "34b-code-q5_1",
            "34b-code-q8_0",
            "34b-code-q2_K",
            "34b-code-q3_K_S",
            "34b-code-q3_K_M",
            "34b-code-q3_K_L",
            "34b-code-q4_K_S",
            "34b-code-q4_K_M",
            "34b-code-q5_K_S",
            "34b-code-q5_K_M",
            "34b-code-q6_K",
            "34b-instruct-q4_0",
            "34b-instruct-q4_1",
            "34b-instruct-q5_0",
            "34b-instruct-q5_1",
            "34b-instruct-q8_0",
            "34b-instruct-q2_K",
            "34b-instruct-q3_K_S",
            "34b-instruct-q3_K_M",
            "34b-instruct-q3_K_L",
            "34b-instruct-q4_K_S",
            "34b-instruct-q4_K_M",
            "34b-instruct-q5_K_S",
            "34b-instruct-q5_K_M",
            "34b-instruct-q6_K",
            "34b-instruct-fp16",
            "34b-python-q4_0",
            "34b-python-q4_1",
            "34b-python-q5_0",
            "34b-python-q5_1",
            "34b-python-q8_0",
            "34b-python-q2_K",
            "34b-python-q3_K_S",
            "34b-python-q3_K_M",
            "34b-python-q3_K_L",
            "34b-python-q4_K_S",
            "34b-python-q4_K_M",
            "34b-python-q5_K_S",
            "34b-python-q5_K_M",
            "34b-python-q6_K",
            "34b-python-fp16",
            "70b-code-q4_0",
            "70b-code-q4_1",
            "70b-code-q5_0",
            "70b-code-q5_1",
            "70b-code-q8_0",
            "70b-code-q2_K",
            "70b-code-q3_K_S",
            "70b-code-q3_K_M",
            "70b-code-q3_K_L",
            "70b-code-q4_K_S",
            "70b-code-q4_K_M",
            "70b-code-q5_K_S",
            "70b-code-q5_K_M",
            "70b-code-q6_K",
            "70b-code-fp16",
            "70b-instruct-q4_0",
            "70b-instruct-q4_1",
            "70b-instruct-q5_0",
            "70b-instruct-q5_1",
            "70b-instruct-q8_0",
            "70b-instruct-q2_K",
            "70b-instruct-q3_K_S",
            "70b-instruct-q3_K_M",
            "70b-instruct-q3_K_L",
            "70b-instruct-q4_K_S",
            "70b-instruct-q4_K_M",
            "70b-instruct-q5_K_S",
            "70b-instruct-q5_K_M",
            "70b-instruct-q6_K",
            "70b-instruct-fp16",
            "70b-python-q4_0",
            "70b-python-q4_1",
            "70b-python-q5_0",
            "70b-python-q5_1",
            "70b-python-q8_0",
            "70b-python-q2_K",
            "70b-python-q3_K_S",
            "70b-python-q3_K_M",
            "70b-python-q3_K_L",
            "70b-python-q4_K_S",
            "70b-python-q4_K_M",
            "70b-python-q5_K_S",
            "70b-python-q5_K_M",
            "70b-python-q6_K",
            "70b-python-fp16"
        ]
    },
    "dolphin-mixtral": {
        "description": "An uncensored, fine-tuned model based on the Mixtral mixture of experts model that excels at coding tasks. Created by Eric Hartford.",
        "tags": [
            "latest",
            "8x7b",
            "v2.7",
            "v2.6.1",
            "v2.5",
            "v2.6",
            "8x7b-v2.5",
            "8x7b-v2.6.1",
            "8x7b-v2.7",
            "8x7b-v2.6",
            "8x7b-v2.5-q4_0",
            "8x7b-v2.5-q4_1",
            "8x7b-v2.5-q5_0",
            "8x7b-v2.5-q5_1",
            "8x7b-v2.5-q8_0",
            "8x7b-v2.5-q2_K",
            "8x7b-v2.5-q3_K_S",
            "8x7b-v2.5-q3_K_M",
            "8x7b-v2.5-q3_K_L",
            "8x7b-v2.5-q4_K_S",
            "8x7b-v2.5-q4_K_M",
            "8x7b-v2.5-q5_K_S",
            "8x7b-v2.5-q5_K_M",
            "8x7b-v2.5-q6_K",
            "8x7b-v2.5-fp16",
            "8x7b-v2.6-q4_0",
            "8x7b-v2.6-q4_1",
            "8x7b-v2.6-q5_0",
            "8x7b-v2.6-q5_1",
            "8x7b-v2.6-q8_0",
            "8x7b-v2.6-q2_K",
            "8x7b-v2.6-q3_K_S",
            "8x7b-v2.6-q3_K_M",
            "8x7b-v2.6-q3_K_L",
            "8x7b-v2.6-q4_K_S",
            "8x7b-v2.6-q4_K_M",
            "8x7b-v2.6-q5_K_S",
            "8x7b-v2.6-q5_K_M",
            "8x7b-v2.6-q6_K",
            "8x7b-v2.6-fp16",
            "8x7b-v2.6.1-q4_0",
            "8x7b-v2.6.1-q4_1",
            "8x7b-v2.6.1-q5_0",
            "8x7b-v2.6.1-q5_1",
            "8x7b-v2.6.1-q8_0",
            "8x7b-v2.6.1-q2_K",
            "8x7b-v2.6.1-q3_K_S",
            "8x7b-v2.6.1-q3_K_M",
            "8x7b-v2.6.1-q3_K_L",
            "8x7b-v2.6.1-q4_K_S",
            "8x7b-v2.6.1-q4_K_M",
            "8x7b-v2.6.1-q5_K_S",
            "8x7b-v2.6.1-q5_K_M",
            "8x7b-v2.6.1-q6_K",
            "8x7b-v2.6.1-fp16",
            "8x7b-v2.7-q4_0",
            "8x7b-v2.7-q4_1",
            "8x7b-v2.7-q5_0",
            "8x7b-v2.7-q5_1",
            "8x7b-v2.7-q8_0",
            "8x7b-v2.7-q2_K",
            "8x7b-v2.7-q3_K_S",
            "8x7b-v2.7-q3_K_M",
            "8x7b-v2.7-q3_K_L",
            "8x7b-v2.7-q4_K_S",
            "8x7b-v2.7-q4_K_M",
            "8x7b-v2.7-q5_K_S",
            "8x7b-v2.7-q5_K_M",
            "8x7b-v2.7-q6_K",
            "8x7b-v2.7-fp16"
        ]
    },
    "mistral-openorca": {
        "description": "Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.",
        "tags": [
            "latest",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16"
        ]
    },
    "llama2-uncensored": {
        "description": "Uncensored Llama 2 model by George Sung and Jarrad Hope.",
        "tags": [
            "latest",
            "7b",
            "70b",
            "7b-chat",
            "70b-chat",
            "7b-chat-q4_0",
            "7b-chat-q4_1",
            "7b-chat-q5_0",
            "7b-chat-q5_1",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K",
            "7b-chat-fp16",
            "70b-chat-q4_0",
            "70b-chat-q4_1",
            "70b-chat-q5_0",
            "70b-chat-q5_1",
            "70b-chat-q8_0",
            "70b-chat-q2_K",
            "70b-chat-q3_K_S",
            "70b-chat-q3_K_M",
            "70b-chat-q3_K_L",
            "70b-chat-q4_K_S",
            "70b-chat-q4_K_M",
            "70b-chat-q5_K_S",
            "70b-chat-q5_K_M",
            "70b-chat-q6_K"
        ]
    },
    "mixtral": {
        "description": "A high-quality Mixture of Experts (MoE) model with open weights by Mistral AI.",
        "tags": [
            "latest",
            "text",
            "8x7b",
            "instruct",
            "8x7b-instruct-v0.1-q4_0",
            "8x7b-instruct-v0.1-q4_1",
            "8x7b-instruct-v0.1-q5_0",
            "8x7b-instruct-v0.1-q5_1",
            "8x7b-instruct-v0.1-q8_0",
            "8x7b-instruct-v0.1-q2_K",
            "8x7b-instruct-v0.1-q3_K_S",
            "8x7b-instruct-v0.1-q3_K_M",
            "8x7b-instruct-v0.1-q3_K_L",
            "8x7b-instruct-v0.1-q4_K_S",
            "8x7b-instruct-v0.1-q4_K_M",
            "8x7b-instruct-v0.1-q5_K_S",
            "8x7b-instruct-v0.1-q5_K_M",
            "8x7b-instruct-v0.1-q6_K",
            "8x7b-instruct-v0.1-fp16",
            "8x7b-text-v0.1-q4_0",
            "8x7b-text-v0.1-q4_1",
            "8x7b-text-v0.1-q5_0",
            "8x7b-text-v0.1-q5_1",
            "8x7b-text-v0.1-q8_0",
            "8x7b-text-v0.1-q2_K",
            "8x7b-text-v0.1-q3_K_S",
            "8x7b-text-v0.1-q3_K_M",
            "8x7b-text-v0.1-q3_K_L",
            "8x7b-text-v0.1-q4_K_S",
            "8x7b-text-v0.1-q4_K_M",
            "8x7b-text-v0.1-q5_K_S",
            "8x7b-text-v0.1-q5_K_M",
            "8x7b-text-v0.1-q6_K",
            "8x7b-text-v0.1-fp16"
        ]
    },
    "llava": {
        "description": "\ud83c\udf0b LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.",
        "tags": [
            "latest",
            "7b",
            "v1.6",
            "13b",
            "34b",
            "7b-v1.6",
            "13b-v1.6",
            "34b-v1.6",
            "7b-v1.5-q4_0",
            "7b-v1.5-q4_1",
            "7b-v1.5-q5_0",
            "7b-v1.5-q5_1",
            "7b-v1.5-q8_0",
            "7b-v1.5-q2_K",
            "7b-v1.5-q3_K_S",
            "7b-v1.5-q3_K_M",
            "7b-v1.5-q3_K_L",
            "7b-v1.5-q4_K_S",
            "7b-v1.5-q4_K_M",
            "7b-v1.5-q5_K_S",
            "7b-v1.5-q5_K_M",
            "7b-v1.5-q6_K",
            "7b-v1.5-fp16",
            "13b-v1.5-q4_0",
            "13b-v1.5-q4_1",
            "13b-v1.5-q5_0",
            "13b-v1.5-q5_1",
            "13b-v1.5-q8_0",
            "13b-v1.5-q2_K",
            "13b-v1.5-q3_K_S",
            "13b-v1.5-q3_K_M",
            "13b-v1.5-q3_K_L",
            "13b-v1.5-q4_K_S",
            "13b-v1.5-q4_K_M",
            "13b-v1.5-q5_K_S",
            "13b-v1.5-q5_K_M",
            "13b-v1.5-q6_K",
            "13b-v1.5-fp16",
            "34b-v1.6-q4_0",
            "34b-v1.6-q4_1",
            "34b-v1.6-q5_0",
            "34b-v1.6-q5_1",
            "34b-v1.6-q8_0",
            "34b-v1.6-q2_K",
            "34b-v1.6-q3_K_S",
            "34b-v1.6-q3_K_M",
            "34b-v1.6-q3_K_L",
            "34b-v1.6-q4_K_S",
            "34b-v1.6-q4_K_M",
            "34b-v1.6-q5_K_S",
            "34b-v1.6-q5_K_M",
            "34b-v1.6-q6_K",
            "34b-v1.6-fp16",
            "7b-v1.6-mistral-q4_0",
            "7b-v1.6-mistral-q4_1",
            "7b-v1.6-mistral-q5_0",
            "7b-v1.6-mistral-q5_1",
            "7b-v1.6-mistral-q8_0",
            "7b-v1.6-mistral-q2_K",
            "7b-v1.6-mistral-q3_K_S",
            "7b-v1.6-mistral-q3_K_M",
            "7b-v1.6-mistral-q3_K_L",
            "7b-v1.6-mistral-q4_K_S",
            "7b-v1.6-mistral-q4_K_M",
            "7b-v1.6-mistral-q5_K_S",
            "7b-v1.6-mistral-q5_K_M",
            "7b-v1.6-mistral-q6_K",
            "7b-v1.6-mistral-fp16",
            "7b-v1.6-vicuna-q4_0",
            "7b-v1.6-vicuna-q4_1",
            "7b-v1.6-vicuna-q5_0",
            "7b-v1.6-vicuna-q5_1",
            "7b-v1.6-vicuna-q8_0",
            "7b-v1.6-vicuna-q2_K",
            "7b-v1.6-vicuna-q3_K_S",
            "7b-v1.6-vicuna-q3_K_M",
            "7b-v1.6-vicuna-q3_K_L",
            "7b-v1.6-vicuna-q4_K_S",
            "7b-v1.6-vicuna-q4_K_M",
            "7b-v1.6-vicuna-q5_K_S",
            "7b-v1.6-vicuna-q5_K_M",
            "7b-v1.6-vicuna-q6_K",
            "7b-v1.6-vicuna-fp16",
            "13b-v1.6-vicuna-q4_0",
            "13b-v1.6-vicuna-q4_1",
            "13b-v1.6-vicuna-q5_0",
            "13b-v1.6-vicuna-q5_1",
            "13b-v1.6-vicuna-q8_0",
            "13b-v1.6-vicuna-q2_K",
            "13b-v1.6-vicuna-q3_K_S",
            "13b-v1.6-vicuna-q3_K_M",
            "13b-v1.6-vicuna-q3_K_L",
            "13b-v1.6-vicuna-q4_K_S",
            "13b-v1.6-vicuna-q4_K_M",
            "13b-v1.6-vicuna-q5_K_S",
            "13b-v1.6-vicuna-q5_K_M",
            "13b-v1.6-vicuna-q6_K",
            "13b-v1.6-vicuna-fp16"
        ]
    },
    "orca-mini": {
        "description": "A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.",
        "tags": [
            "latest",
            "7b",
            "3b",
            "13b",
            "70b",
            "7b-v3",
            "13b-v3",
            "70b-v3",
            "3b-q4_0",
            "3b-q4_1",
            "3b-q5_0",
            "3b-q5_1",
            "3b-q8_0",
            "3b-fp16",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "7b-v2-q4_0",
            "7b-v2-q4_1",
            "7b-v2-q5_0",
            "7b-v2-q5_1",
            "7b-v2-q8_0",
            "7b-v2-q2_K",
            "7b-v2-q3_K_S",
            "7b-v2-q3_K_M",
            "7b-v2-q3_K_L",
            "7b-v2-q4_K_S",
            "7b-v2-q4_K_M",
            "7b-v2-q5_K_S",
            "7b-v2-q5_K_M",
            "7b-v2-q6_K",
            "7b-v2-fp16",
            "7b-v3-q4_0",
            "7b-v3-q4_1",
            "7b-v3-q5_0",
            "7b-v3-q5_1",
            "7b-v3-q8_0",
            "7b-v3-q2_K",
            "7b-v3-q3_K_S",
            "7b-v3-q3_K_M",
            "7b-v3-q3_K_L",
            "7b-v3-q4_K_S",
            "7b-v3-q4_K_M",
            "7b-v3-q5_K_S",
            "7b-v3-q5_K_M",
            "7b-v3-q6_K",
            "7b-v3-fp16",
            "13b-v2-q4_0",
            "13b-v2-q4_1",
            "13b-v2-q5_0",
            "13b-v2-q5_1",
            "13b-v2-q8_0",
            "13b-v2-q2_K",
            "13b-v2-q3_K_S",
            "13b-v2-q3_K_M",
            "13b-v2-q3_K_L",
            "13b-v2-q4_K_S",
            "13b-v2-q4_K_M",
            "13b-v2-q5_K_S",
            "13b-v2-q5_K_M",
            "13b-v2-q6_K",
            "13b-v2-fp16",
            "13b-v3-q4_0",
            "13b-v3-q4_1",
            "13b-v3-q5_0",
            "13b-v3-q5_1",
            "13b-v3-q8_0",
            "13b-v3-q2_K",
            "13b-v3-q3_K_S",
            "13b-v3-q3_K_M",
            "13b-v3-q3_K_L",
            "13b-v3-q4_K_S",
            "13b-v3-q4_K_M",
            "13b-v3-q5_K_S",
            "13b-v3-q5_K_M",
            "13b-v3-q6_K",
            "13b-v3-fp16",
            "70b-v3-q4_0",
            "70b-v3-q4_1",
            "70b-v3-q5_0",
            "70b-v3-q5_1",
            "70b-v3-q8_0",
            "70b-v3-q2_K",
            "70b-v3-q3_K_S",
            "70b-v3-q3_K_M",
            "70b-v3-q3_K_L",
            "70b-v3-q4_K_S",
            "70b-v3-q4_K_M",
            "70b-v3-q5_K_S",
            "70b-v3-q5_K_M",
            "70b-v3-q6_K",
            "70b-v3-fp16"
        ]
    },
    "phi": {
        "description": "Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.",
        "tags": [
            "latest",
            "2.7b",
            "chat",
            "2.7b-chat-v2-q4_0",
            "2.7b-chat-v2-q4_1",
            "2.7b-chat-v2-q5_0",
            "2.7b-chat-v2-q5_1",
            "2.7b-chat-v2-q8_0",
            "2.7b-chat-v2-q2_K",
            "2.7b-chat-v2-q3_K_S",
            "2.7b-chat-v2-q3_K_M",
            "2.7b-chat-v2-q3_K_L",
            "2.7b-chat-v2-q4_K_S",
            "2.7b-chat-v2-q4_K_M",
            "2.7b-chat-v2-q5_K_S",
            "2.7b-chat-v2-q5_K_M",
            "2.7b-chat-v2-q6_K",
            "2.7b-chat-v2-fp16"
        ]
    },
    "gemma": {
        "description": "Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind.",
        "tags": [
            "latest",
            "text",
            "2b",
            "7b",
            "instruct",
            "2b-instruct",
            "2b-text",
            "7b-text",
            "7b-instruct",
            "2b-instruct-q4_0",
            "2b-instruct-q4_1",
            "2b-instruct-q5_0",
            "2b-instruct-q5_1",
            "2b-instruct-q8_0",
            "2b-instruct-q2_K",
            "2b-instruct-q3_K_S",
            "2b-instruct-q3_K_M",
            "2b-instruct-q3_K_L",
            "2b-instruct-q4_K_S",
            "2b-instruct-q4_K_M",
            "2b-instruct-q5_K_S",
            "2b-instruct-q5_K_M",
            "2b-instruct-q6_K",
            "2b-instruct-fp16",
            "2b-text-q4_0",
            "2b-text-q4_1",
            "2b-text-q5_0",
            "2b-text-q5_1",
            "2b-text-q8_0",
            "2b-text-q2_K",
            "2b-text-q3_K_S",
            "2b-text-q3_K_M",
            "2b-text-q3_K_L",
            "2b-text-q4_K_S",
            "2b-text-q4_K_M",
            "2b-text-q5_K_S",
            "2b-text-q5_K_M",
            "2b-text-q6_K",
            "2b-text-fp16",
            "7b-instruct-q4_0",
            "7b-instruct-q4_1",
            "7b-instruct-q5_0",
            "7b-instruct-q5_1",
            "7b-instruct-q8_0",
            "7b-instruct-q2_K",
            "7b-instruct-q3_K_S",
            "7b-instruct-q3_K_M",
            "7b-instruct-q3_K_L",
            "7b-instruct-q4_K_S",
            "7b-instruct-q4_K_M",
            "7b-instruct-q5_K_S",
            "7b-instruct-q5_K_M",
            "7b-instruct-q6_K",
            "7b-instruct-fp16",
            "7b-text-q4_0",
            "7b-text-q4_1",
            "7b-text-q5_0",
            "7b-text-q5_1",
            "7b-text-q8_0",
            "7b-text-q2_K",
            "7b-text-q3_K_S",
            "7b-text-q3_K_M",
            "7b-text-q3_K_L",
            "7b-text-q4_K_S",
            "7b-text-q4_K_M",
            "7b-text-q5_K_S",
            "7b-text-q5_K_M",
            "7b-text-q6_K",
            "7b-text-fp16"
        ]
    },
    "deepseek-coder": {
        "description": "DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.",
        "tags": [
            "latest",
            "1.3b",
            "base",
            "33b",
            "6.7b",
            "instruct",
            "1.3b-base",
            "1.3b-instruct",
            "6.7b-base",
            "6.7b-instruct",
            "33b-instruct",
            "33b-base",
            "1.3b-base-q4_0",
            "1.3b-base-q4_1",
            "1.3b-base-q5_0",
            "1.3b-base-q5_1",
            "1.3b-base-q8_0",
            "1.3b-base-q2_K",
            "1.3b-base-q3_K_S",
            "1.3b-base-q3_K_M",
            "1.3b-base-q3_K_L",
            "1.3b-base-q4_K_S",
            "1.3b-base-q4_K_M",
            "1.3b-base-q5_K_S",
            "1.3b-base-q5_K_M",
            "1.3b-base-q6_K",
            "1.3b-base-fp16",
            "1.3b-instruct-q4_0",
            "1.3b-instruct-q4_1",
            "1.3b-instruct-q5_0",
            "1.3b-instruct-q5_1",
            "1.3b-instruct-q8_0",
            "1.3b-instruct-q2_K",
            "1.3b-instruct-q3_K_S",
            "1.3b-instruct-q3_K_M",
            "1.3b-instruct-q3_K_L",
            "1.3b-instruct-q4_K_S",
            "1.3b-instruct-q4_K_M",
            "1.3b-instruct-q5_K_S",
            "1.3b-instruct-q5_K_M",
            "1.3b-instruct-q6_K",
            "1.3b-instruct-fp16",
            "6.7b-base-q4_0",
            "6.7b-base-q4_1",
            "6.7b-base-q5_0",
            "6.7b-base-q5_1",
            "6.7b-base-q8_0",
            "6.7b-base-q2_K",
            "6.7b-base-q3_K_S",
            "6.7b-base-q3_K_M",
            "6.7b-base-q3_K_L",
            "6.7b-base-q4_K_S",
            "6.7b-base-q4_K_M",
            "6.7b-base-q5_K_S",
            "6.7b-base-q5_K_M",
            "6.7b-base-q6_K",
            "6.7b-base-fp16",
            "6.7b-instruct-q4_0",
            "6.7b-instruct-q4_1",
            "6.7b-instruct-q5_0",
            "6.7b-instruct-q5_1",
            "6.7b-instruct-q8_0",
            "6.7b-instruct-q2_K",
            "6.7b-instruct-q3_K_S",
            "6.7b-instruct-q3_K_M",
            "6.7b-instruct-q3_K_L",
            "6.7b-instruct-q4_K_S",
            "6.7b-instruct-q4_K_M",
            "6.7b-instruct-q5_K_S",
            "6.7b-instruct-q5_K_M",
            "6.7b-instruct-q6_K",
            "6.7b-instruct-fp16",
            "33b-base-q4_0",
            "33b-base-q4_1",
            "33b-base-q5_0",
            "33b-base-q5_1",
            "33b-base-q8_0",
            "33b-base-q2_K",
            "33b-base-q3_K_S",
            "33b-base-q3_K_M",
            "33b-base-q3_K_L",
            "33b-base-q4_K_S",
            "33b-base-q4_K_M",
            "33b-base-q5_K_S",
            "33b-base-q5_K_M",
            "33b-base-q6_K",
            "33b-base-fp16",
            "33b-instruct-q4_0",
            "33b-instruct-q4_1",
            "33b-instruct-q5_0",
            "33b-instruct-q5_1",
            "33b-instruct-q8_0",
            "33b-instruct-q2_K",
            "33b-instruct-q3_K_S",
            "33b-instruct-q3_K_M",
            "33b-instruct-q3_K_L",
            "33b-instruct-q4_K_S",
            "33b-instruct-q4_K_M",
            "33b-instruct-q5_K_S",
            "33b-instruct-q5_K_M",
            "33b-instruct-q6_K",
            "33b-instruct-fp16"
        ]
    },
    "dolphin-mistral": {
        "description": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.6.",
        "tags": [
            "latest",
            "v2.2",
            "v2.1",
            "v2.6",
            "7b",
            "v2",
            "v2.2.1",
            "7b-v2",
            "7b-v2.2",
            "7b-v2.2.1",
            "7b-v2.1",
            "7b-v2.6",
            "7b-v2.6-dpo-laser",
            "7b-v2-q4_0",
            "7b-v2-q4_1",
            "7b-v2-q5_0",
            "7b-v2-q5_1",
            "7b-v2-q8_0",
            "7b-v2-q2_K",
            "7b-v2-q3_K_S",
            "7b-v2-q3_K_M",
            "7b-v2-q3_K_L",
            "7b-v2-q4_K_S",
            "7b-v2-q4_K_M",
            "7b-v2-q5_K_S",
            "7b-v2-q5_K_M",
            "7b-v2-q6_K",
            "7b-v2-fp16",
            "7b-v2.1-q4_0",
            "7b-v2.1-q4_1",
            "7b-v2.1-q5_0",
            "7b-v2.1-q5_1",
            "7b-v2.1-q8_0",
            "7b-v2.1-q2_K",
            "7b-v2.1-q3_K_S",
            "7b-v2.1-q3_K_M",
            "7b-v2.1-q3_K_L",
            "7b-v2.1-q4_K_S",
            "7b-v2.1-q4_K_M",
            "7b-v2.1-q5_K_S",
            "7b-v2.1-q5_K_M",
            "7b-v2.1-q6_K",
            "7b-v2.1-fp16",
            "7b-v2.2-q4_0",
            "7b-v2.2-q4_1",
            "7b-v2.2-q5_0",
            "7b-v2.2-q5_1",
            "7b-v2.2-q8_0",
            "7b-v2.2-q2_K",
            "7b-v2.2-q3_K_S",
            "7b-v2.2-q3_K_M",
            "7b-v2.2-q3_K_L",
            "7b-v2.2-q4_K_S",
            "7b-v2.2-q4_K_M",
            "7b-v2.2-q5_K_S",
            "7b-v2.2-q5_K_M",
            "7b-v2.2-q6_K",
            "7b-v2.2-fp16",
            "7b-v2.2.1-q4_0",
            "7b-v2.2.1-q4_1",
            "7b-v2.2.1-q5_0",
            "7b-v2.2.1-q5_1",
            "7b-v2.2.1-q8_0",
            "7b-v2.2.1-q2_K",
            "7b-v2.2.1-q3_K_S",
            "7b-v2.2.1-q3_K_M",
            "7b-v2.2.1-q3_K_L",
            "7b-v2.2.1-q4_K_S",
            "7b-v2.2.1-q4_K_M",
            "7b-v2.2.1-q5_K_S",
            "7b-v2.2.1-q5_K_M",
            "7b-v2.2.1-q6_K",
            "7b-v2.2.1-fp16",
            "7b-v2.6-q4_0",
            "7b-v2.6-q4_1",
            "7b-v2.6-q5_0",
            "7b-v2.6-q5_1",
            "7b-v2.6-q8_0",
            "7b-v2.6-q2_K",
            "7b-v2.6-q3_K_S",
            "7b-v2.6-q3_K_M",
            "7b-v2.6-q3_K_L",
            "7b-v2.6-q4_K_S",
            "7b-v2.6-q4_K_M",
            "7b-v2.6-q5_K_S",
            "7b-v2.6-q5_K_M",
            "7b-v2.6-q6_K",
            "7b-v2.6-fp16",
            "7b-v2.6-dpo-laser-q4_0",
            "7b-v2.6-dpo-laser-q4_1",
            "7b-v2.6-dpo-laser-q5_0",
            "7b-v2.6-dpo-laser-q5_1",
            "7b-v2.6-dpo-laser-q8_0",
            "7b-v2.6-dpo-laser-q2_K",
            "7b-v2.6-dpo-laser-q3_K_S",
            "7b-v2.6-dpo-laser-q3_K_M",
            "7b-v2.6-dpo-laser-q3_K_L",
            "7b-v2.6-dpo-laser-q4_K_S",
            "7b-v2.6-dpo-laser-q4_K_M",
            "7b-v2.6-dpo-laser-q5_K_S",
            "7b-v2.6-dpo-laser-q5_K_M",
            "7b-v2.6-dpo-laser-q6_K",
            "7b-v2.6-dpo-laser-fp16"
        ]
    },
    "vicuna": {
        "description": "General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.",
        "tags": [
            "latest",
            "13b",
            "33b",
            "7b",
            "7b-16k",
            "13b-16k",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "33b-q4_0",
            "33b-q4_1",
            "33b-q5_0",
            "33b-q5_1",
            "33b-q8_0",
            "33b-q2_K",
            "33b-q3_K_S",
            "33b-q3_K_M",
            "33b-q3_K_L",
            "33b-q4_K_S",
            "33b-q4_K_M",
            "33b-q5_K_S",
            "33b-q5_K_M",
            "33b-q6_K",
            "33b-fp16",
            "7b-v1.5-q4_0",
            "7b-v1.5-q4_1",
            "7b-v1.5-q5_0",
            "7b-v1.5-q5_1",
            "7b-v1.5-q8_0",
            "7b-v1.5-q2_K",
            "7b-v1.5-q3_K_S",
            "7b-v1.5-q3_K_M",
            "7b-v1.5-q3_K_L",
            "7b-v1.5-q4_K_S",
            "7b-v1.5-q4_K_M",
            "7b-v1.5-q5_K_S",
            "7b-v1.5-q5_K_M",
            "7b-v1.5-q6_K",
            "7b-v1.5-fp16",
            "13b-v1.5-q4_0",
            "13b-v1.5-q4_1",
            "13b-v1.5-q5_0",
            "13b-v1.5-q5_1",
            "13b-v1.5-q8_0",
            "13b-v1.5-q2_K",
            "13b-v1.5-q3_K_S",
            "13b-v1.5-q3_K_M",
            "13b-v1.5-q3_K_L",
            "13b-v1.5-q4_K_S",
            "13b-v1.5-q4_K_M",
            "13b-v1.5-q5_K_S",
            "13b-v1.5-q5_K_M",
            "13b-v1.5-q6_K",
            "13b-v1.5-fp16",
            "7b-v1.5-16k-q4_0",
            "7b-v1.5-16k-q4_1",
            "7b-v1.5-16k-q5_0",
            "7b-v1.5-16k-q5_1",
            "7b-v1.5-16k-q8_0",
            "7b-v1.5-16k-q2_K",
            "7b-v1.5-16k-q3_K_S",
            "7b-v1.5-16k-q3_K_M",
            "7b-v1.5-16k-q3_K_L",
            "7b-v1.5-16k-q4_K_S",
            "7b-v1.5-16k-q4_K_M",
            "7b-v1.5-16k-q5_K_S",
            "7b-v1.5-16k-q5_K_M",
            "7b-v1.5-16k-q6_K",
            "7b-v1.5-16k-fp16",
            "13b-v1.5-16k-q4_0",
            "13b-v1.5-16k-q4_1",
            "13b-v1.5-16k-q5_0",
            "13b-v1.5-16k-q5_1",
            "13b-v1.5-16k-q8_0",
            "13b-v1.5-16k-q2_K",
            "13b-v1.5-16k-q3_K_S",
            "13b-v1.5-16k-q3_K_M",
            "13b-v1.5-16k-q3_K_L",
            "13b-v1.5-16k-q4_K_S",
            "13b-v1.5-16k-q4_K_M",
            "13b-v1.5-16k-q5_K_S",
            "13b-v1.5-16k-q5_K_M",
            "13b-v1.5-16k-q6_K",
            "13b-v1.5-16k-fp16"
        ]
    },
    "wizard-vicuna-uncensored": {
        "description": "Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford.",
        "tags": [
            "latest",
            "30b",
            "7b",
            "13b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "30b-q4_0",
            "30b-q4_1",
            "30b-q5_0",
            "30b-q5_1",
            "30b-q8_0",
            "30b-q2_K",
            "30b-q3_K_S",
            "30b-q3_K_M",
            "30b-q3_K_L",
            "30b-q4_K_S",
            "30b-q4_K_M",
            "30b-q5_K_S",
            "30b-q5_K_M",
            "30b-q6_K",
            "30b-fp16"
        ]
    },
    "zephyr": {
        "description": "Zephyr beta is a fine-tuned 7B version of mistral that was trained on on a mix of publicly available, synthetic datasets.",
        "tags": [
            "latest",
            "7b",
            "7b-beta",
            "7b-alpha",
            "7b-alpha-q4_0",
            "7b-alpha-q4_1",
            "7b-alpha-q5_0",
            "7b-alpha-q5_1",
            "7b-alpha-q8_0",
            "7b-alpha-q2_K",
            "7b-alpha-q3_K_S",
            "7b-alpha-q3_K_M",
            "7b-alpha-q3_K_L",
            "7b-alpha-q4_K_S",
            "7b-alpha-q4_K_M",
            "7b-alpha-q5_K_S",
            "7b-alpha-q5_K_M",
            "7b-alpha-q6_K",
            "7b-alpha-fp16",
            "7b-beta-q4_0",
            "7b-beta-q4_1",
            "7b-beta-q5_0",
            "7b-beta-q5_1",
            "7b-beta-q8_0",
            "7b-beta-q2_K",
            "7b-beta-q3_K_S",
            "7b-beta-q3_K_M",
            "7b-beta-q3_K_L",
            "7b-beta-q4_K_S",
            "7b-beta-q4_K_M",
            "7b-beta-q5_K_S",
            "7b-beta-q5_K_M",
            "7b-beta-q6_K",
            "7b-beta-fp16"
        ]
    },
    "openhermes": {
        "description": "OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.",
        "tags": [
            "latest",
            "v2.5",
            "v2",
            "7b-v2",
            "7b-v2.5",
            "7b-mistral-v2-q4_0",
            "7b-mistral-v2-q4_1",
            "7b-mistral-v2-q5_0",
            "7b-mistral-v2-q5_1",
            "7b-mistral-v2-q8_0",
            "7b-mistral-v2-q2_K",
            "7b-mistral-v2-q3_K_S",
            "7b-mistral-v2-q3_K_M",
            "7b-mistral-v2-q3_K_L",
            "7b-mistral-v2-q4_K_S",
            "7b-mistral-v2-q4_K_M",
            "7b-mistral-v2-q5_K_S",
            "7b-mistral-v2-q5_K_M",
            "7b-mistral-v2-q6_K",
            "7b-mistral-v2-fp16",
            "7b-mistral-v2.5-q4_0",
            "7b-mistral-v2.5-q4_1",
            "7b-mistral-v2.5-q5_0",
            "7b-mistral-v2.5-q5_1",
            "7b-mistral-v2.5-q8_0",
            "7b-mistral-v2.5-q2_K",
            "7b-mistral-v2.5-q3_K_S",
            "7b-mistral-v2.5-q3_K_M",
            "7b-mistral-v2.5-q3_K_L",
            "7b-mistral-v2.5-q4_K_S",
            "7b-mistral-v2.5-q4_K_M",
            "7b-mistral-v2.5-q5_K_S",
            "7b-mistral-v2.5-q5_K_M",
            "7b-mistral-v2.5-q6_K",
            "7b-mistral-v2.5-fp16"
        ]
    },
    "wizardcoder": {
        "description": "State-of-the-art code generation model",
        "tags": [
            "latest",
            "33b",
            "python",
            "7b-python",
            "13b-python",
            "33b-v1.1",
            "34b-python",
            "7b-python-q4_0",
            "7b-python-q4_1",
            "7b-python-q5_0",
            "7b-python-q5_1",
            "7b-python-q8_0",
            "7b-python-q2_K",
            "7b-python-q3_K_S",
            "7b-python-q3_K_M",
            "7b-python-q3_K_L",
            "7b-python-q4_K_S",
            "7b-python-q4_K_M",
            "7b-python-q5_K_S",
            "7b-python-q5_K_M",
            "7b-python-q6_K",
            "7b-python-fp16",
            "13b-python-q4_0",
            "13b-python-q4_1",
            "13b-python-q5_0",
            "13b-python-q5_1",
            "13b-python-q8_0",
            "13b-python-q2_K",
            "13b-python-q3_K_S",
            "13b-python-q3_K_M",
            "13b-python-q3_K_L",
            "13b-python-q4_K_S",
            "13b-python-q4_K_M",
            "13b-python-q5_K_S",
            "13b-python-q5_K_M",
            "13b-python-q6_K",
            "13b-python-fp16",
            "33b-v1.1-q4_0",
            "33b-v1.1-q4_1",
            "33b-v1.1-q5_0",
            "33b-v1.1-q5_1",
            "33b-v1.1-q8_0",
            "33b-v1.1-q2_K",
            "33b-v1.1-q3_K_S",
            "33b-v1.1-q3_K_M",
            "33b-v1.1-q3_K_L",
            "33b-v1.1-q4_K_S",
            "33b-v1.1-q4_K_M",
            "33b-v1.1-q5_K_S",
            "33b-v1.1-q5_K_M",
            "33b-v1.1-q6_K",
            "33b-v1.1-fp16",
            "34b-python-q4_0",
            "34b-python-q4_1",
            "34b-python-q5_0",
            "34b-python-q5_1",
            "34b-python-q8_0",
            "34b-python-q2_K",
            "34b-python-q3_K_S",
            "34b-python-q3_K_M",
            "34b-python-q3_K_L",
            "34b-python-q4_K_S",
            "34b-python-q4_K_M",
            "34b-python-q5_K_S",
            "34b-python-q5_K_M",
            "34b-python-q6_K",
            "34b-python-fp16"
        ]
    },
    "qwen": {
        "description": "Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 72B parameters",
        "tags": [
            "latest",
            "14b",
            "4b",
            "1.8b",
            "0.5b",
            "7b",
            "72b",
            "0.5b-text",
            "0.5b-chat",
            "1.8b-text",
            "1.8b-chat",
            "4b-chat",
            "4b-text",
            "7b-chat",
            "7b-text",
            "14b-text",
            "14b-chat",
            "72b-text",
            "72b-chat",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "1.8b-chat-q4_0",
            "1.8b-chat-q4_1",
            "1.8b-chat-q5_0",
            "1.8b-chat-q5_1",
            "1.8b-chat-q8_0",
            "1.8b-chat-q2_K",
            "1.8b-chat-q3_K_S",
            "1.8b-chat-q3_K_M",
            "1.8b-chat-q3_K_L",
            "1.8b-chat-q4_K_S",
            "1.8b-chat-q4_K_M",
            "1.8b-chat-q5_K_S",
            "1.8b-chat-q5_K_M",
            "1.8b-chat-q6_K",
            "1.8b-chat-fp16",
            "1.8b-text-q4_0",
            "1.8b-text-q4_1",
            "1.8b-text-q5_0",
            "1.8b-text-q5_1",
            "1.8b-text-q8_0",
            "1.8b-text-q2_K",
            "1.8b-text-q3_K_S",
            "1.8b-text-q3_K_M",
            "1.8b-text-q3_K_L",
            "1.8b-text-q4_K_S",
            "1.8b-text-q4_K_M",
            "1.8b-text-q5_K_S",
            "1.8b-text-q5_K_M",
            "1.8b-text-q6_K",
            "1.8b-text-fp16",
            "7b-chat-q4_0",
            "7b-chat-q4_1",
            "7b-chat-q5_0",
            "7b-chat-q5_1",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K",
            "7b-chat-fp16",
            "14b-chat-q4_0",
            "14b-chat-q4_1",
            "14b-chat-q5_0",
            "14b-chat-q5_1",
            "14b-chat-q8_0",
            "14b-chat-q2_K",
            "14b-chat-q3_K_S",
            "14b-chat-q3_K_M",
            "14b-chat-q3_K_L",
            "14b-chat-q4_K_S",
            "14b-chat-q4_K_M",
            "14b-chat-q5_K_S",
            "14b-chat-q5_K_M",
            "14b-chat-q6_K",
            "14b-chat-fp16",
            "14b-text-q4_0",
            "14b-text-q4_1",
            "14b-text-q5_0",
            "14b-text-q5_1",
            "14b-text-q8_0",
            "14b-text-q2_K",
            "14b-text-q3_K_S",
            "14b-text-q3_K_M",
            "14b-text-q3_K_L",
            "14b-text-q4_K_S",
            "14b-text-q4_K_M",
            "14b-text-q5_K_S",
            "14b-text-q5_K_M",
            "14b-text-q6_K",
            "14b-text-fp16",
            "72b-chat-q4_0",
            "72b-chat-q4_1",
            "72b-chat-q5_0",
            "72b-chat-q5_1",
            "72b-chat-q8_0",
            "72b-chat-q2_K",
            "72b-chat-q3_K_S",
            "72b-chat-q3_K_M",
            "72b-chat-q3_K_L",
            "72b-chat-q4_K_S",
            "72b-chat-q4_K_M",
            "72b-chat-q5_K_S",
            "72b-chat-q5_K_M",
            "72b-chat-q6_K",
            "72b-chat-fp16",
            "72b-text-q4_0",
            "72b-text-q4_1",
            "72b-text-q5_0",
            "72b-text-q5_1",
            "72b-text-q8_0",
            "72b-text-q2_K",
            "72b-text-q3_K_S",
            "72b-text-q3_K_M",
            "72b-text-q3_K_L",
            "72b-text-q4_K_S",
            "72b-text-q4_K_M",
            "72b-text-q5_K_S",
            "72b-text-q5_K_M",
            "72b-text-q6_K",
            "72b-text-fp16",
            "0.5b-chat-v1.5-q4_0",
            "0.5b-chat-v1.5-q4_1",
            "0.5b-chat-v1.5-q5_0",
            "0.5b-chat-v1.5-q5_1",
            "0.5b-chat-v1.5-q8_0",
            "0.5b-chat-v1.5-q2_K",
            "0.5b-chat-v1.5-q3_K_S",
            "0.5b-chat-v1.5-q3_K_M",
            "0.5b-chat-v1.5-q3_K_L",
            "0.5b-chat-v1.5-q4_K_S",
            "0.5b-chat-v1.5-q4_K_M",
            "0.5b-chat-v1.5-q5_K_S",
            "0.5b-chat-v1.5-q5_K_M",
            "0.5b-chat-v1.5-q6_K",
            "0.5b-chat-v1.5-fp16",
            "0.5b-text-v1.5-q4_0",
            "0.5b-text-v1.5-q4_1",
            "0.5b-text-v1.5-q5_0",
            "0.5b-text-v1.5-q5_1",
            "0.5b-text-v1.5-q8_0",
            "0.5b-text-v1.5-q2_K",
            "0.5b-text-v1.5-q3_K_S",
            "0.5b-text-v1.5-q3_K_M",
            "0.5b-text-v1.5-q3_K_L",
            "0.5b-text-v1.5-q4_K_S",
            "0.5b-text-v1.5-q4_K_M",
            "0.5b-text-v1.5-q5_K_S",
            "0.5b-text-v1.5-q5_K_M",
            "0.5b-text-v1.5-q6_K",
            "0.5b-text-v1.5-fp16",
            "1.8b-chat-v1.5-q4_0",
            "1.8b-chat-v1.5-q4_1",
            "1.8b-chat-v1.5-q5_0",
            "1.8b-chat-v1.5-q5_1",
            "1.8b-chat-v1.5-q8_0",
            "1.8b-chat-v1.5-q2_K",
            "1.8b-chat-v1.5-q3_K_S",
            "1.8b-chat-v1.5-q3_K_M",
            "1.8b-chat-v1.5-q3_K_L",
            "1.8b-chat-v1.5-q4_K_S",
            "1.8b-chat-v1.5-q4_K_M",
            "1.8b-chat-v1.5-q5_K_S",
            "1.8b-chat-v1.5-q5_K_M",
            "1.8b-chat-v1.5-q6_K",
            "1.8b-chat-v1.5-fp16",
            "1.8b-text-v1.5-q4_0",
            "1.8b-text-v1.5-q4_1",
            "1.8b-text-v1.5-q5_0",
            "1.8b-text-v1.5-q5_1",
            "1.8b-text-v1.5-q8_0",
            "1.8b-text-v1.5-q2_K",
            "1.8b-text-v1.5-q3_K_S",
            "1.8b-text-v1.5-q3_K_M",
            "1.8b-text-v1.5-q3_K_L",
            "1.8b-text-v1.5-q4_K_S",
            "1.8b-text-v1.5-q4_K_M",
            "1.8b-text-v1.5-q5_K_S",
            "1.8b-text-v1.5-q5_K_M",
            "1.8b-text-v1.5-q6_K",
            "1.8b-text-v1.5-fp16",
            "4b-chat-v1.5-q4_0",
            "4b-chat-v1.5-q4_1",
            "4b-chat-v1.5-q5_0",
            "4b-chat-v1.5-q5_1",
            "4b-chat-v1.5-q8_0",
            "4b-chat-v1.5-q2_K",
            "4b-chat-v1.5-q3_K_S",
            "4b-chat-v1.5-q3_K_M",
            "4b-chat-v1.5-q3_K_L",
            "4b-chat-v1.5-q4_K_S",
            "4b-chat-v1.5-q4_K_M",
            "4b-chat-v1.5-q5_K_S",
            "4b-chat-v1.5-q5_K_M",
            "4b-chat-v1.5-q6_K",
            "4b-chat-v1.5-fp16",
            "4b-text-v1.5-q4_0",
            "4b-text-v1.5-q4_1",
            "4b-text-v1.5-q5_0",
            "4b-text-v1.5-q5_1",
            "4b-text-v1.5-q8_0",
            "4b-text-v1.5-q2_K",
            "4b-text-v1.5-q3_K_S",
            "4b-text-v1.5-q3_K_M",
            "4b-text-v1.5-q3_K_L",
            "4b-text-v1.5-q4_K_S",
            "4b-text-v1.5-q4_K_M",
            "4b-text-v1.5-q5_K_S",
            "4b-text-v1.5-q5_K_M",
            "4b-text-v1.5-q6_K",
            "4b-text-v1.5-fp16",
            "7b-chat-v1.5-q4_0",
            "7b-chat-v1.5-q4_1",
            "7b-chat-v1.5-q5_0",
            "7b-chat-v1.5-q5_1",
            "7b-chat-v1.5-q8_0",
            "7b-chat-v1.5-q2_K",
            "7b-chat-v1.5-q3_K_S",
            "7b-chat-v1.5-q3_K_M",
            "7b-chat-v1.5-q3_K_L",
            "7b-chat-v1.5-q4_K_S",
            "7b-chat-v1.5-q4_K_M",
            "7b-chat-v1.5-q5_K_S",
            "7b-chat-v1.5-q5_K_M",
            "7b-chat-v1.5-q6_K",
            "7b-chat-v1.5-fp16",
            "7b-text-v1.5-q4_0",
            "7b-text-v1.5-q4_1",
            "7b-text-v1.5-q5_0",
            "7b-text-v1.5-q5_1",
            "7b-text-v1.5-q8_0",
            "7b-text-v1.5-q2_K",
            "7b-text-v1.5-q3_K_S",
            "7b-text-v1.5-q3_K_M",
            "7b-text-v1.5-q3_K_L",
            "7b-text-v1.5-q4_K_S",
            "7b-text-v1.5-q4_K_M",
            "7b-text-v1.5-q5_K_S",
            "7b-text-v1.5-q5_K_M",
            "7b-text-v1.5-q6_K",
            "7b-text-v1.5-fp16",
            "14b-chat-v1.5-q4_0",
            "14b-chat-v1.5-q4_1",
            "14b-chat-v1.5-q5_0",
            "14b-chat-v1.5-q5_1",
            "14b-chat-v1.5-q8_0",
            "14b-chat-v1.5-q2_K",
            "14b-chat-v1.5-q3_K_S",
            "14b-chat-v1.5-q3_K_M",
            "14b-chat-v1.5-q3_K_L",
            "14b-chat-v1.5-q4_K_S",
            "14b-chat-v1.5-q4_K_M",
            "14b-chat-v1.5-q5_K_S",
            "14b-chat-v1.5-q5_K_M",
            "14b-chat-v1.5-q6_K",
            "14b-chat-v1.5-fp16",
            "14b-text-v1.5-q4_0",
            "14b-text-v1.5-q4_1",
            "14b-text-v1.5-q5_0",
            "14b-text-v1.5-q5_1",
            "14b-text-v1.5-q8_0",
            "14b-text-v1.5-q2_K",
            "14b-text-v1.5-q3_K_S",
            "14b-text-v1.5-q3_K_M",
            "14b-text-v1.5-q3_K_L",
            "14b-text-v1.5-q4_K_S",
            "14b-text-v1.5-q4_K_M",
            "14b-text-v1.5-q5_K_S",
            "14b-text-v1.5-q5_K_M",
            "14b-text-v1.5-q6_K",
            "14b-text-v1.5-fp16",
            "72b-chat-v1.5-q4_0",
            "72b-chat-v1.5-q4_1",
            "72b-chat-v1.5-q5_0",
            "72b-chat-v1.5-q5_1",
            "72b-chat-v1.5-q8_0",
            "72b-chat-v1.5-q2_K",
            "72b-chat-v1.5-q3_K_S",
            "72b-chat-v1.5-q3_K_M",
            "72b-chat-v1.5-q3_K_L",
            "72b-chat-v1.5-q4_K_S",
            "72b-chat-v1.5-q4_K_M",
            "72b-chat-v1.5-q5_K_S",
            "72b-chat-v1.5-q5_K_M",
            "72b-chat-v1.5-q6_K",
            "72b-chat-v1.5-fp16",
            "72b-text-v1.5-q4_0",
            "72b-text-v1.5-q4_1",
            "72b-text-v1.5-q5_0",
            "72b-text-v1.5-q5_1",
            "72b-text-v1.5-q8_0",
            "72b-text-v1.5-q2_K",
            "72b-text-v1.5-q3_K_S",
            "72b-text-v1.5-q3_K_M",
            "72b-text-v1.5-q3_K_L",
            "72b-text-v1.5-q4_K_S",
            "72b-text-v1.5-q4_K_M",
            "72b-text-v1.5-q5_K_S",
            "72b-text-v1.5-q5_K_M",
            "72b-text-v1.5-q6_K",
            "72b-text-v1.5-fp16"
        ]
    },
    "llama2-chinese": {
        "description": "Llama 2 based model fine tuned to improve Chinese dialogue ability.",
        "tags": [
            "latest",
            "13b",
            "7b",
            "7b-chat",
            "13b-chat",
            "7b-chat-q4_0",
            "7b-chat-q4_1",
            "7b-chat-q5_0",
            "7b-chat-q5_1",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K",
            "7b-chat-fp16",
            "13b-chat-q4_0",
            "13b-chat-q4_1",
            "13b-chat-q5_0",
            "13b-chat-q5_1",
            "13b-chat-q8_0",
            "13b-chat-q2_K",
            "13b-chat-q3_K_S",
            "13b-chat-q3_K_M",
            "13b-chat-q3_K_L",
            "13b-chat-q4_K_S",
            "13b-chat-q4_K_M",
            "13b-chat-q5_K_S",
            "13b-chat-q5_K_M",
            "13b-chat-q6_K",
            "13b-chat-fp16"
        ]
    },
    "phind-codellama": {
        "description": "Code generation model based on Code Llama.",
        "tags": [
            "latest",
            "34b",
            "34b-python",
            "34b-v2",
            "34b-q4_0",
            "34b-q4_1",
            "34b-q5_0",
            "34b-q5_1",
            "34b-q8_0",
            "34b-q2_K",
            "34b-q3_K_S",
            "34b-q3_K_M",
            "34b-q3_K_L",
            "34b-q4_K_S",
            "34b-q4_K_M",
            "34b-q5_K_S",
            "34b-q5_K_M",
            "34b-q6_K",
            "34b-fp16",
            "34b-python-q4_0",
            "34b-python-q4_1",
            "34b-python-q5_0",
            "34b-python-q5_1",
            "34b-python-q8_0",
            "34b-python-q2_K",
            "34b-python-q3_K_S",
            "34b-python-q3_K_M",
            "34b-python-q3_K_L",
            "34b-python-q4_K_S",
            "34b-python-q4_K_M",
            "34b-python-q5_K_S",
            "34b-python-q5_K_M",
            "34b-python-q6_K",
            "34b-python-fp16",
            "34b-v2-q4_0",
            "34b-v2-q4_1",
            "34b-v2-q5_0",
            "34b-v2-q5_1",
            "34b-v2-q8_0",
            "34b-v2-q2_K",
            "34b-v2-q3_K_S",
            "34b-v2-q3_K_M",
            "34b-v2-q3_K_L",
            "34b-v2-q4_K_S",
            "34b-v2-q4_K_M",
            "34b-v2-q5_K_S",
            "34b-v2-q5_K_M",
            "34b-v2-q6_K",
            "34b-v2-fp16"
        ]
    },
    "tinyllama": {
        "description": "The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.",
        "tags": [
            "latest",
            "chat",
            "v0.6",
            "1.1b",
            "v1",
            "1.1b-chat",
            "1.1b-chat-v0.6-q4_0",
            "1.1b-chat-v0.6-q4_1",
            "1.1b-chat-v0.6-q5_0",
            "1.1b-chat-v0.6-q5_1",
            "1.1b-chat-v0.6-q8_0",
            "1.1b-chat-v0.6-q2_K",
            "1.1b-chat-v0.6-q3_K_S",
            "1.1b-chat-v0.6-q3_K_M",
            "1.1b-chat-v0.6-q3_K_L",
            "1.1b-chat-v0.6-q4_K_S",
            "1.1b-chat-v0.6-q4_K_M",
            "1.1b-chat-v0.6-q5_K_S",
            "1.1b-chat-v0.6-q5_K_M",
            "1.1b-chat-v0.6-q6_K",
            "1.1b-chat-v0.6-fp16",
            "1.1b-chat-v1-q4_0",
            "1.1b-chat-v1-q4_1",
            "1.1b-chat-v1-q5_0",
            "1.1b-chat-v1-q5_1",
            "1.1b-chat-v1-q8_0",
            "1.1b-chat-v1-q2_K",
            "1.1b-chat-v1-q3_K_S",
            "1.1b-chat-v1-q3_K_M",
            "1.1b-chat-v1-q3_K_L",
            "1.1b-chat-v1-q4_K_S",
            "1.1b-chat-v1-q4_K_M",
            "1.1b-chat-v1-q5_K_S",
            "1.1b-chat-v1-q5_K_M",
            "1.1b-chat-v1-q6_K",
            "1.1b-chat-v1-fp16"
        ]
    },
    "openchat": {
        "description": "A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106.",
        "tags": [
            "latest",
            "7b",
            "7b-v3.5",
            "7b-v3.5-0106",
            "7b-v3.5-1210",
            "7b-v3.5-q4_0",
            "7b-v3.5-q4_1",
            "7b-v3.5-q5_0",
            "7b-v3.5-q5_1",
            "7b-v3.5-q8_0",
            "7b-v3.5-q2_K",
            "7b-v3.5-q3_K_S",
            "7b-v3.5-q3_K_M",
            "7b-v3.5-q3_K_L",
            "7b-v3.5-q4_K_S",
            "7b-v3.5-q4_K_M",
            "7b-v3.5-q5_K_S",
            "7b-v3.5-q5_K_M",
            "7b-v3.5-q6_K",
            "7b-v3.5-fp16",
            "7b-v3.5-0106-q4_0",
            "7b-v3.5-0106-q4_1",
            "7b-v3.5-0106-q5_0",
            "7b-v3.5-0106-q5_1",
            "7b-v3.5-0106-q8_0",
            "7b-v3.5-0106-q2_K",
            "7b-v3.5-0106-q3_K_S",
            "7b-v3.5-0106-q3_K_M",
            "7b-v3.5-0106-q3_K_L",
            "7b-v3.5-0106-q4_K_S",
            "7b-v3.5-0106-q4_K_M",
            "7b-v3.5-0106-q5_K_S",
            "7b-v3.5-0106-q5_K_M",
            "7b-v3.5-0106-q6_K",
            "7b-v3.5-0106-fp16",
            "7b-v3.5-1210-q4_0",
            "7b-v3.5-1210-q4_1",
            "7b-v3.5-1210-q5_0",
            "7b-v3.5-1210-q5_1",
            "7b-v3.5-1210-q8_0",
            "7b-v3.5-1210-q2_K",
            "7b-v3.5-1210-q3_K_S",
            "7b-v3.5-1210-q3_K_M",
            "7b-v3.5-1210-q3_K_L",
            "7b-v3.5-1210-q4_K_S",
            "7b-v3.5-1210-q4_K_M",
            "7b-v3.5-1210-q5_K_S",
            "7b-v3.5-1210-q5_K_M",
            "7b-v3.5-1210-q6_K",
            "7b-v3.5-1210-fp16"
        ]
    },
    "orca2": {
        "description": "Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models.  The model is designed to excel particularly in reasoning.",
        "tags": [
            "latest",
            "13b",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16"
        ]
    },
    "neural-chat": {
        "description": "A fine-tuned model based on Mistral with good coverage of domain and language.",
        "tags": [
            "latest",
            "7b",
            "7b-v3.1",
            "7b-v3.2",
            "7b-v3.3",
            "7b-v3.1-q4_0",
            "7b-v3.1-q4_1",
            "7b-v3.1-q5_0",
            "7b-v3.1-q5_1",
            "7b-v3.1-q8_0",
            "7b-v3.1-q2_K",
            "7b-v3.1-q3_K_S",
            "7b-v3.1-q3_K_M",
            "7b-v3.1-q3_K_L",
            "7b-v3.1-q4_K_S",
            "7b-v3.1-q4_K_M",
            "7b-v3.1-q5_K_S",
            "7b-v3.1-q5_K_M",
            "7b-v3.1-q6_K",
            "7b-v3.1-fp16",
            "7b-v3.2-q4_0",
            "7b-v3.2-q4_1",
            "7b-v3.2-q5_0",
            "7b-v3.2-q5_1",
            "7b-v3.2-q8_0",
            "7b-v3.2-q2_K",
            "7b-v3.2-q3_K_S",
            "7b-v3.2-q3_K_M",
            "7b-v3.2-q3_K_L",
            "7b-v3.2-q4_K_S",
            "7b-v3.2-q4_K_M",
            "7b-v3.2-q5_K_S",
            "7b-v3.2-q5_K_M",
            "7b-v3.2-q6_K",
            "7b-v3.2-fp16",
            "7b-v3.3-q4_0",
            "7b-v3.3-q4_1",
            "7b-v3.3-q5_0",
            "7b-v3.3-q5_1",
            "7b-v3.3-q8_0",
            "7b-v3.3-q2_K",
            "7b-v3.3-q3_K_S",
            "7b-v3.3-q3_K_M",
            "7b-v3.3-q3_K_L",
            "7b-v3.3-q4_K_S",
            "7b-v3.3-q4_K_M",
            "7b-v3.3-q5_K_S",
            "7b-v3.3-q5_K_M",
            "7b-v3.3-q6_K",
            "7b-v3.3-fp16"
        ]
    },
    "falcon": {
        "description": "A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.",
        "tags": [
            "latest",
            "text",
            "180b",
            "40b",
            "7b",
            "instruct",
            "7b-instruct",
            "7b-text",
            "40b-text",
            "40b-instruct",
            "180b-chat",
            "180b-text",
            "7b-instruct-q4_0",
            "7b-instruct-q4_1",
            "7b-instruct-q5_0",
            "7b-instruct-q5_1",
            "7b-instruct-q8_0",
            "7b-instruct-fp16",
            "7b-text-q4_0",
            "7b-text-q4_1",
            "7b-text-q5_0",
            "7b-text-q5_1",
            "7b-text-q8_0",
            "7b-text-fp16",
            "40b-instruct-q4_0",
            "40b-instruct-q4_1",
            "40b-instruct-q5_0",
            "40b-instruct-q5_1",
            "40b-instruct-q8_0",
            "40b-instruct-fp16",
            "40b-text-q4_0",
            "40b-text-q4_1",
            "40b-text-q5_0",
            "40b-text-q5_1",
            "40b-text-q8_0",
            "40b-text-fp16",
            "180b-chat-q4_0",
            "180b-text-q4_0"
        ]
    },
    "wizard-math": {
        "description": "Model focused on math and logic problems",
        "tags": [
            "latest",
            "13b",
            "70b",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "70b-q4_0",
            "70b-q4_1",
            "70b-q5_0",
            "70b-q5_1",
            "70b-q8_0",
            "70b-q2_K",
            "70b-q3_K_S",
            "70b-q3_K_M",
            "70b-q3_K_L",
            "70b-q4_K_S",
            "70b-q4_K_M",
            "70b-q5_K_S",
            "70b-q5_K_M",
            "70b-q6_K",
            "70b-fp16",
            "7b-v1.1-q4_0",
            "7b-v1.1-q4_1",
            "7b-v1.1-q5_0",
            "7b-v1.1-q5_1",
            "7b-v1.1-q8_0",
            "7b-v1.1-q2_K",
            "7b-v1.1-q3_K_S",
            "7b-v1.1-q3_K_M",
            "7b-v1.1-q3_K_L",
            "7b-v1.1-q4_K_S",
            "7b-v1.1-q4_K_M",
            "7b-v1.1-q5_K_S",
            "7b-v1.1-q5_K_M",
            "7b-v1.1-q6_K",
            "7b-v1.1-fp16"
        ]
    },
    "nous-hermes": {
        "description": "General use models based on Llama and Llama 2 from Nous Research.",
        "tags": [
            "latest",
            "7b",
            "13b",
            "7b-llama2",
            "13b-llama2",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "7b-llama2-q4_0",
            "7b-llama2-q4_1",
            "7b-llama2-q5_0",
            "7b-llama2-q5_1",
            "7b-llama2-q8_0",
            "7b-llama2-q2_K",
            "7b-llama2-q3_K_S",
            "7b-llama2-q3_K_M",
            "7b-llama2-q3_K_L",
            "7b-llama2-q4_K_S",
            "7b-llama2-q4_K_M",
            "7b-llama2-q5_K_S",
            "7b-llama2-q5_K_M",
            "7b-llama2-q6_K",
            "7b-llama2-fp16",
            "13b-llama2-q4_0",
            "13b-llama2-q4_1",
            "13b-llama2-q5_0",
            "13b-llama2-q5_1",
            "13b-llama2-q8_0",
            "13b-llama2-q2_K",
            "13b-llama2-q3_K_S",
            "13b-llama2-q3_K_M",
            "13b-llama2-q3_K_L",
            "13b-llama2-q4_K_S",
            "13b-llama2-q4_K_M",
            "13b-llama2-q5_K_S",
            "13b-llama2-q5_K_M",
            "13b-llama2-q6_K",
            "13b-llama2-fp16",
            "70b-llama2-q4_0",
            "70b-llama2-q4_1",
            "70b-llama2-q5_0",
            "70b-llama2-q5_1",
            "70b-llama2-q2_K",
            "70b-llama2-q3_K_S",
            "70b-llama2-q3_K_M",
            "70b-llama2-q3_K_L",
            "70b-llama2-q4_K_S",
            "70b-llama2-q4_K_M",
            "70b-llama2-q5_K_M",
            "70b-llama2-q6_K",
            "70b-llama2-fp16"
        ]
    },
    "yi": {
        "description": "A high-performing, bilingual language model.",
        "tags": [
            "latest",
            "6b",
            "34b",
            "6b-200k",
            "6b-chat",
            "34b-chat",
            "6b-q4_0",
            "6b-q4_1",
            "6b-q5_0",
            "6b-q5_1",
            "6b-q8_0",
            "6b-q2_K",
            "6b-q3_K_S",
            "6b-q3_K_M",
            "6b-q3_K_L",
            "6b-q4_K_S",
            "6b-q4_K_M",
            "6b-q5_K_S",
            "6b-q5_K_M",
            "6b-q6_K",
            "6b-fp16",
            "34b-q4_0",
            "34b-q4_1",
            "34b-q5_0",
            "34b-q5_1",
            "34b-q2_K",
            "34b-q3_K_S",
            "34b-q3_K_M",
            "34b-q3_K_L",
            "34b-q4_K_S",
            "34b-q4_K_M",
            "34b-q5_K_S",
            "34b-q6_K",
            "6b-200k-q4_0",
            "6b-200k-q4_1",
            "6b-200k-q5_0",
            "6b-200k-q5_1",
            "6b-200k-q8_0",
            "6b-200k-q2_K",
            "6b-200k-q3_K_S",
            "6b-200k-q3_K_M",
            "6b-200k-q3_K_L",
            "6b-200k-q4_K_S",
            "6b-200k-q4_K_M",
            "6b-200k-q5_K_S",
            "6b-200k-q5_K_M",
            "6b-200k-q6_K",
            "6b-200k-fp16",
            "6b-chat-q4_0",
            "6b-chat-q4_1",
            "6b-chat-q5_0",
            "6b-chat-q5_1",
            "6b-chat-q8_0",
            "6b-chat-q2_K",
            "6b-chat-q3_K_S",
            "6b-chat-q3_K_M",
            "6b-chat-q3_K_L",
            "6b-chat-q4_K_S",
            "6b-chat-q4_K_M",
            "6b-chat-q5_K_S",
            "6b-chat-q5_K_M",
            "6b-chat-q6_K",
            "6b-chat-fp16",
            "34b-chat-q4_0",
            "34b-chat-q4_1",
            "34b-chat-q5_0",
            "34b-chat-q5_1",
            "34b-chat-q8_0",
            "34b-chat-q2_K",
            "34b-chat-q3_K_S",
            "34b-chat-q3_K_M",
            "34b-chat-q3_K_L",
            "34b-chat-q4_K_S",
            "34b-chat-q4_K_M",
            "34b-chat-q5_K_S",
            "34b-chat-q5_K_M",
            "34b-chat-q6_K",
            "34b-chat-fp16"
        ]
    },
    "dolphin-phi": {
        "description": "2.7B uncensored Dolphin model by Eric Hartford, based on the Phi language model by Microsoft Research.",
        "tags": [
            "latest",
            "2.7b",
            "2.7b-v2.6",
            "2.7b-v2.6-q4_0",
            "2.7b-v2.6-q5_0",
            "2.7b-v2.6-q8_0",
            "2.7b-v2.6-q2_K",
            "2.7b-v2.6-q3_K_S",
            "2.7b-v2.6-q3_K_M",
            "2.7b-v2.6-q3_K_L",
            "2.7b-v2.6-q4_K_S",
            "2.7b-v2.6-q4_K_M",
            "2.7b-v2.6-q5_K_S",
            "2.7b-v2.6-q5_K_M",
            "2.7b-v2.6-q6_K"
        ]
    },
    "tinydolphin": {
        "description": "An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.",
        "tags": [
            "latest",
            "1.1b",
            "v2.8",
            "1.1b-v2.8-q4_0",
            "1.1b-v2.8-q4_1",
            "1.1b-v2.8-q5_0",
            "1.1b-v2.8-q5_1",
            "1.1b-v2.8-q8_0",
            "1.1b-v2.8-q2_K",
            "1.1b-v2.8-q3_K_S",
            "1.1b-v2.8-q3_K_M",
            "1.1b-v2.8-q3_K_L",
            "1.1b-v2.8-q4_K_S",
            "1.1b-v2.8-q4_K_M",
            "1.1b-v2.8-q5_K_S",
            "1.1b-v2.8-q5_K_M",
            "1.1b-v2.8-q6_K",
            "1.1b-v2.8-fp16"
        ]
    },
    "starling-lm": {
        "description": "Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.",
        "tags": [
            "latest",
            "7b",
            "7b-alpha",
            "7b-alpha-q4_0",
            "7b-alpha-q4_1",
            "7b-alpha-q5_0",
            "7b-alpha-q5_1",
            "7b-alpha-q8_0",
            "7b-alpha-q2_K",
            "7b-alpha-q3_K_S",
            "7b-alpha-q3_K_M",
            "7b-alpha-q3_K_L",
            "7b-alpha-q4_K_S",
            "7b-alpha-q4_K_M",
            "7b-alpha-q5_K_S",
            "7b-alpha-q5_K_M",
            "7b-alpha-q6_K",
            "7b-alpha-fp16"
        ]
    },
    "codeup": {
        "description": "Great code generation model based on Llama2.",
        "tags": [
            "latest",
            "13b",
            "13b-llama2",
            "13b-llama2-chat",
            "13b-llama2-chat-q4_0",
            "13b-llama2-chat-q4_1",
            "13b-llama2-chat-q5_0",
            "13b-llama2-chat-q5_1",
            "13b-llama2-chat-q8_0",
            "13b-llama2-chat-q2_K",
            "13b-llama2-chat-q3_K_S",
            "13b-llama2-chat-q3_K_M",
            "13b-llama2-chat-q3_K_L",
            "13b-llama2-chat-q4_K_S",
            "13b-llama2-chat-q4_K_M",
            "13b-llama2-chat-q5_K_S",
            "13b-llama2-chat-q5_K_M",
            "13b-llama2-chat-q6_K",
            "13b-llama2-chat-fp16"
        ]
    },
    "starcoder": {
        "description": "StarCoder is a code generation model trained on 80+ programming languages.",
        "tags": [
            "latest",
            "1b",
            "15b",
            "3b",
            "7b",
            "1b-base",
            "3b-base",
            "7b-base",
            "15b-base",
            "15b-plus",
            "15b-q4_0",
            "15b-q4_1",
            "15b-q5_0",
            "15b-q5_1",
            "15b-q8_0",
            "15b-q2_K",
            "15b-q3_K_S",
            "15b-q3_K_M",
            "15b-q3_K_L",
            "15b-q4_K_S",
            "15b-q4_K_M",
            "15b-q5_K_S",
            "15b-q5_K_M",
            "15b-q6_K",
            "15b-fp16",
            "1b-base-q4_0",
            "1b-base-q4_1",
            "1b-base-q5_0",
            "1b-base-q5_1",
            "1b-base-q8_0",
            "1b-base-q2_K",
            "1b-base-q3_K_S",
            "1b-base-q3_K_M",
            "1b-base-q3_K_L",
            "1b-base-q4_K_S",
            "1b-base-q4_K_M",
            "1b-base-q5_K_S",
            "1b-base-q5_K_M",
            "1b-base-q6_K",
            "1b-base-fp16",
            "3b-base-q4_0",
            "3b-base-q4_1",
            "3b-base-q5_0",
            "3b-base-q5_1",
            "3b-base-q8_0",
            "3b-base-q2_K",
            "3b-base-q3_K_S",
            "3b-base-q3_K_M",
            "3b-base-q3_K_L",
            "3b-base-q4_K_S",
            "3b-base-q4_K_M",
            "3b-base-q5_K_S",
            "3b-base-q5_K_M",
            "3b-base-q6_K",
            "3b-base-fp16",
            "7b-base-q4_0",
            "7b-base-q4_1",
            "7b-base-q5_0",
            "7b-base-q5_1",
            "7b-base-q8_0",
            "7b-base-q2_K",
            "7b-base-q3_K_S",
            "7b-base-q3_K_M",
            "7b-base-q3_K_L",
            "7b-base-q4_K_S",
            "7b-base-q4_K_M",
            "7b-base-q5_K_S",
            "7b-base-q5_K_M",
            "7b-base-q6_K",
            "7b-base-fp16",
            "15b-base-q4_0",
            "15b-base-q4_1",
            "15b-base-q5_0",
            "15b-base-q5_1",
            "15b-base-q8_0",
            "15b-base-q2_K",
            "15b-base-q3_K_S",
            "15b-base-q3_K_M",
            "15b-base-q3_K_L",
            "15b-base-q4_K_S",
            "15b-base-q4_K_M",
            "15b-base-q5_K_S",
            "15b-base-q5_K_M",
            "15b-base-q6_K",
            "15b-base-fp16",
            "15b-plus-q4_0",
            "15b-plus-q4_1",
            "15b-plus-q5_0",
            "15b-plus-q5_1",
            "15b-plus-q8_0",
            "15b-plus-q2_K",
            "15b-plus-q3_K_S",
            "15b-plus-q3_K_M",
            "15b-plus-q3_K_L",
            "15b-plus-q4_K_S",
            "15b-plus-q4_K_M",
            "15b-plus-q5_K_S",
            "15b-plus-q5_K_M",
            "15b-plus-q6_K",
            "15b-plus-fp16"
        ]
    },
    "medllama2": {
        "description": "Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.",
        "tags": [
            "latest",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16"
        ]
    },
    "wizardlm-uncensored": {
        "description": "Uncensored version of Wizard LM model",
        "tags": [
            "latest",
            "13b",
            "13b-llama2",
            "13b-llama2-q4_0",
            "13b-llama2-q4_1",
            "13b-llama2-q5_0",
            "13b-llama2-q5_1",
            "13b-llama2-q8_0",
            "13b-llama2-q2_K",
            "13b-llama2-q3_K_S",
            "13b-llama2-q3_K_M",
            "13b-llama2-q3_K_L",
            "13b-llama2-q4_K_S",
            "13b-llama2-q4_K_M",
            "13b-llama2-q5_K_S",
            "13b-llama2-q5_K_M",
            "13b-llama2-q6_K",
            "13b-llama2-fp16"
        ]
    },
    "bakllava": {
        "description": "BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA  architecture.",
        "tags": [
            "latest",
            "7b",
            "7b-v1-q4_0",
            "7b-v1-q4_1",
            "7b-v1-q5_0",
            "7b-v1-q5_1",
            "7b-v1-q8_0",
            "7b-v1-q2_K",
            "7b-v1-q3_K_S",
            "7b-v1-q3_K_M",
            "7b-v1-q3_K_L",
            "7b-v1-q4_K_S",
            "7b-v1-q4_K_M",
            "7b-v1-q5_K_S",
            "7b-v1-q5_K_M",
            "7b-v1-q6_K",
            "7b-v1-fp16"
        ]
    },
    "everythinglm": {
        "description": "Uncensored Llama2 based model with support for a 16K context window.",
        "tags": [
            "latest",
            "13b",
            "13b-16k",
            "13b-16k-q4_0",
            "13b-16k-q4_1",
            "13b-16k-q5_0",
            "13b-16k-q5_1",
            "13b-16k-q8_0",
            "13b-16k-q2_K",
            "13b-16k-q3_K_S",
            "13b-16k-q3_K_M",
            "13b-16k-q3_K_L",
            "13b-16k-q4_K_S",
            "13b-16k-q4_K_M",
            "13b-16k-q5_K_S",
            "13b-16k-q5_K_M",
            "13b-16k-q6_K",
            "13b-16k-fp16"
        ]
    },
    "stable-code": {
        "description": "Stable Code 3B is a model offering accurate and responsive code completion at a level on par with models such as CodeLLaMA 7B that are 2.5x larger.",
        "tags": [
            "latest",
            "code",
            "3b",
            "3b-code-q4_0",
            "3b-code-q4_1",
            "3b-code-q5_0",
            "3b-code-q5_1",
            "3b-code-q8_0",
            "3b-code-q2_K",
            "3b-code-q3_K_S",
            "3b-code-q3_K_M",
            "3b-code-q3_K_L",
            "3b-code-q4_K_S",
            "3b-code-q4_K_M",
            "3b-code-q5_K_S",
            "3b-code-q5_K_M",
            "3b-code-q6_K",
            "3b-code-fp16"
        ]
    },
    "solar": {
        "description": "A compact, yet powerful 10.7B large language model designed for single-turn conversation.",
        "tags": [
            "latest",
            "10.7b",
            "10.7b-instruct-v1-q4_0",
            "10.7b-instruct-v1-q4_1",
            "10.7b-instruct-v1-q5_0",
            "10.7b-instruct-v1-q5_1",
            "10.7b-instruct-v1-q8_0",
            "10.7b-instruct-v1-q2_K",
            "10.7b-instruct-v1-q3_K_S",
            "10.7b-instruct-v1-q3_K_M",
            "10.7b-instruct-v1-q3_K_L",
            "10.7b-instruct-v1-q4_K_S",
            "10.7b-instruct-v1-q4_K_M",
            "10.7b-instruct-v1-q5_K_S",
            "10.7b-instruct-v1-q5_K_M",
            "10.7b-instruct-v1-q6_K",
            "10.7b-instruct-v1-fp16",
            "10.7b-text-v1-q4_0",
            "10.7b-text-v1-q4_1",
            "10.7b-text-v1-q5_0",
            "10.7b-text-v1-q5_1",
            "10.7b-text-v1-q8_0",
            "10.7b-text-v1-q2_K",
            "10.7b-text-v1-q3_K_S",
            "10.7b-text-v1-q3_K_M",
            "10.7b-text-v1-q3_K_L",
            "10.7b-text-v1-q4_K_S",
            "10.7b-text-v1-q4_K_M",
            "10.7b-text-v1-q5_K_S",
            "10.7b-text-v1-q5_K_M",
            "10.7b-text-v1-q6_K",
            "10.7b-text-v1-fp16"
        ]
    },
    "stable-beluga": {
        "description": "Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.",
        "tags": [
            "latest",
            "70b",
            "13b",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "70b-q4_0",
            "70b-q4_1",
            "70b-q5_0",
            "70b-q5_1",
            "70b-q8_0",
            "70b-q2_K",
            "70b-q3_K_S",
            "70b-q3_K_M",
            "70b-q3_K_L",
            "70b-q4_K_S",
            "70b-q4_K_M",
            "70b-q5_K_S",
            "70b-q5_K_M",
            "70b-q6_K",
            "70b-fp16"
        ]
    },
    "sqlcoder": {
        "description": "SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks",
        "tags": [
            "latest",
            "15b",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "15b-q4_0",
            "15b-q4_1",
            "15b-q5_0",
            "15b-q5_1",
            "15b-q8_0",
            "15b-q2_K",
            "15b-q3_K_S",
            "15b-q3_K_M",
            "15b-q3_K_L",
            "15b-q4_K_S",
            "15b-q4_K_M",
            "15b-q5_K_S",
            "15b-q5_K_M",
            "15b-q6_K",
            "15b-fp16",
            "70b-alpha-q4_0",
            "70b-alpha-q4_1",
            "70b-alpha-q5_0",
            "70b-alpha-q5_1",
            "70b-alpha-q8_0",
            "70b-alpha-q2_K",
            "70b-alpha-q3_K_S",
            "70b-alpha-q3_K_M",
            "70b-alpha-q3_K_L",
            "70b-alpha-q4_K_S",
            "70b-alpha-q4_K_M",
            "70b-alpha-q5_K_S",
            "70b-alpha-q5_K_M",
            "70b-alpha-q6_K",
            "70b-alpha-fp16"
        ]
    },
    "yarn-mistral": {
        "description": "An extension of Mistral to support context windows of 64K or 128K.",
        "tags": [
            "latest",
            "7b",
            "7b-64k",
            "7b-128k",
            "7b-64k-q4_0",
            "7b-64k-q4_1",
            "7b-64k-q5_0",
            "7b-64k-q5_1",
            "7b-64k-q8_0",
            "7b-64k-q2_K",
            "7b-64k-q3_K_S",
            "7b-64k-q3_K_M",
            "7b-64k-q3_K_L",
            "7b-64k-q4_K_S",
            "7b-64k-q4_K_M",
            "7b-64k-q5_K_S",
            "7b-64k-q5_K_M",
            "7b-64k-q6_K",
            "7b-128k-q4_0",
            "7b-128k-q4_1",
            "7b-128k-q5_0",
            "7b-128k-q5_1",
            "7b-128k-q8_0",
            "7b-128k-q2_K",
            "7b-128k-q3_K_S",
            "7b-128k-q3_K_M",
            "7b-128k-q3_K_L",
            "7b-128k-q4_K_S",
            "7b-128k-q4_K_M",
            "7b-128k-q5_K_S",
            "7b-128k-q5_K_M",
            "7b-128k-q6_K",
            "7b-128k-fp16"
        ]
    },
    "nous-hermes2-mixtral": {
        "description": "The Nous Hermes 2 model from Nous Research, now trained over Mixtral.",
        "tags": [
            "latest",
            "dpo",
            "8x7b",
            "8x7b-dpo-q4_0",
            "8x7b-dpo-q4_1",
            "8x7b-dpo-q5_0",
            "8x7b-dpo-q5_1",
            "8x7b-dpo-q8_0",
            "8x7b-dpo-q2_K",
            "8x7b-dpo-q3_K_S",
            "8x7b-dpo-q3_K_M",
            "8x7b-dpo-q3_K_L",
            "8x7b-dpo-q4_K_S",
            "8x7b-dpo-q4_K_M",
            "8x7b-dpo-q5_K_S",
            "8x7b-dpo-q5_K_M",
            "8x7b-dpo-q6_K",
            "8x7b-dpo-fp16"
        ]
    },
    "samantha-mistral": {
        "description": "A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.",
        "tags": [
            "latest",
            "7b",
            "7b-text",
            "7b-v1.2-text",
            "7b-instruct-q4_0",
            "7b-instruct-q4_1",
            "7b-instruct-q5_0",
            "7b-instruct-q5_1",
            "7b-instruct-q8_0",
            "7b-instruct-q2_K",
            "7b-instruct-q3_K_S",
            "7b-instruct-q3_K_M",
            "7b-instruct-q3_K_L",
            "7b-instruct-q4_K_S",
            "7b-instruct-q4_K_M",
            "7b-instruct-q5_K_S",
            "7b-instruct-q5_K_M",
            "7b-instruct-q6_K",
            "7b-instruct-fp16",
            "7b-text-q4_0",
            "7b-text-q4_1",
            "7b-text-q5_0",
            "7b-text-q5_1",
            "7b-text-q8_0",
            "7b-text-q2_K",
            "7b-text-q3_K_S",
            "7b-text-q3_K_M",
            "7b-text-q3_K_L",
            "7b-text-q4_K_S",
            "7b-text-q4_K_M",
            "7b-text-q5_K_S",
            "7b-text-q5_K_M",
            "7b-text-q6_K",
            "7b-text-fp16",
            "7b-v1.2-text-q4_0",
            "7b-v1.2-text-q4_1",
            "7b-v1.2-text-q5_0",
            "7b-v1.2-text-q5_1",
            "7b-v1.2-text-q8_0",
            "7b-v1.2-text-q2_K",
            "7b-v1.2-text-q3_K_S",
            "7b-v1.2-text-q3_K_M",
            "7b-v1.2-text-q3_K_L",
            "7b-v1.2-text-q4_K_S",
            "7b-v1.2-text-q4_K_M",
            "7b-v1.2-text-q5_K_S",
            "7b-v1.2-text-q5_K_M",
            "7b-v1.2-text-q6_K",
            "7b-v1.2-text-fp16"
        ]
    },
    "stablelm-zephyr": {
        "description": "A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.",
        "tags": [
            "latest",
            "3b",
            "3b-q4_0",
            "3b-q4_1",
            "3b-q5_0",
            "3b-q5_1",
            "3b-q8_0",
            "3b-q2_K",
            "3b-q3_K_S",
            "3b-q3_K_M",
            "3b-q3_K_L",
            "3b-q4_K_S",
            "3b-q4_K_M",
            "3b-q5_K_S",
            "3b-q5_K_M",
            "3b-q6_K",
            "3b-fp16"
        ]
    },
    "meditron": {
        "description": "Open-source medical large language model adapted from Llama 2 to the medical domain.",
        "tags": [
            "latest",
            "70b",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "70b-q4_0",
            "70b-q4_1",
            "70b-q5_1",
            "70b-q4_K_S"
        ]
    },
    "wizard-vicuna": {
        "description": "Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.",
        "tags": [
            "latest",
            "13b",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16"
        ]
    },
    "magicoder": {
        "description": "\ud83c\udfa9 Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets.",
        "tags": [
            "latest",
            "7b",
            "7b-s-cl",
            "7b-s-cl-q4_0",
            "7b-s-cl-q4_1",
            "7b-s-cl-q5_0",
            "7b-s-cl-q5_1",
            "7b-s-cl-q8_0",
            "7b-s-cl-q2_K",
            "7b-s-cl-q3_K_S",
            "7b-s-cl-q3_K_M",
            "7b-s-cl-q3_K_L",
            "7b-s-cl-q4_K_S",
            "7b-s-cl-q4_K_M",
            "7b-s-cl-q5_K_S",
            "7b-s-cl-q5_K_M",
            "7b-s-cl-q6_K",
            "7b-s-cl-fp16"
        ]
    },
    "stablelm2": {
        "description": "Stable LM 2 1.6B is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",
        "tags": [
            "latest",
            "zephyr",
            "1.6b",
            "1.6b-zephyr",
            "1.6b-q4_0",
            "1.6b-q4_1",
            "1.6b-q5_0",
            "1.6b-q5_1",
            "1.6b-q8_0",
            "1.6b-q2_K",
            "1.6b-q3_K_S",
            "1.6b-q3_K_M",
            "1.6b-q3_K_L",
            "1.6b-q4_K_S",
            "1.6b-q4_K_M",
            "1.6b-q5_K_S",
            "1.6b-q5_K_M",
            "1.6b-q6_K",
            "1.6b-fp16",
            "1.6b-zephyr-q4_0",
            "1.6b-zephyr-q4_1",
            "1.6b-zephyr-q5_0",
            "1.6b-zephyr-q5_1",
            "1.6b-zephyr-q8_0",
            "1.6b-zephyr-q2_K",
            "1.6b-zephyr-q3_K_S",
            "1.6b-zephyr-q3_K_M",
            "1.6b-zephyr-q3_K_L",
            "1.6b-zephyr-q4_K_S",
            "1.6b-zephyr-q4_K_M",
            "1.6b-zephyr-q5_K_S",
            "1.6b-zephyr-q5_K_M",
            "1.6b-zephyr-q6_K",
            "1.6b-zephyr-fp16"
        ]
    },
    "yarn-llama2": {
        "description": "An extension of Llama 2 that supports a context of up to 128k tokens.",
        "tags": [
            "latest",
            "7b",
            "13b",
            "7b-64k",
            "7b-128k",
            "13b-64k",
            "13b-128k",
            "7b-64k-q4_0",
            "7b-64k-q4_1",
            "7b-64k-q5_0",
            "7b-64k-q5_1",
            "7b-64k-q8_0",
            "7b-64k-q2_K",
            "7b-64k-q3_K_S",
            "7b-64k-q3_K_M",
            "7b-64k-q3_K_L",
            "7b-64k-q4_K_S",
            "7b-64k-q4_K_M",
            "7b-64k-q5_K_S",
            "7b-64k-q5_K_M",
            "7b-64k-q6_K",
            "7b-64k-fp16",
            "7b-128k-q4_0",
            "7b-128k-q4_1",
            "7b-128k-q5_0",
            "7b-128k-q5_1",
            "7b-128k-q8_0",
            "7b-128k-q2_K",
            "7b-128k-q3_K_S",
            "7b-128k-q3_K_M",
            "7b-128k-q3_K_L",
            "7b-128k-q4_K_S",
            "7b-128k-q4_K_M",
            "7b-128k-q5_K_S",
            "7b-128k-q5_K_M",
            "7b-128k-q6_K",
            "7b-128k-fp16",
            "13b-64k-q4_0",
            "13b-64k-q4_1",
            "13b-64k-q5_0",
            "13b-64k-q5_1",
            "13b-64k-q8_0",
            "13b-64k-q2_K",
            "13b-64k-q3_K_S",
            "13b-64k-q3_K_M",
            "13b-64k-q3_K_L",
            "13b-64k-q4_K_S",
            "13b-64k-q4_K_M",
            "13b-64k-q5_K_S",
            "13b-64k-q5_K_M",
            "13b-64k-q6_K",
            "13b-64k-fp16",
            "13b-128k-q4_0",
            "13b-128k-q4_1",
            "13b-128k-q5_0",
            "13b-128k-q5_1",
            "13b-128k-q8_0",
            "13b-128k-q2_K",
            "13b-128k-q3_K_S",
            "13b-128k-q3_K_M",
            "13b-128k-q3_K_L",
            "13b-128k-q4_K_S",
            "13b-128k-q4_K_M",
            "13b-128k-q5_K_S",
            "13b-128k-q5_K_M",
            "13b-128k-q6_K",
            "13b-128k-fp16"
        ]
    },
    "nous-hermes2": {
        "description": "The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.",
        "tags": [
            "latest",
            "34b",
            "10.7b",
            "10.7b-solar-q4_0",
            "10.7b-solar-q4_1",
            "10.7b-solar-q5_0",
            "10.7b-solar-q5_1",
            "10.7b-solar-q8_0",
            "10.7b-solar-q2_K",
            "10.7b-solar-q3_K_S",
            "10.7b-solar-q3_K_M",
            "10.7b-solar-q3_K_L",
            "10.7b-solar-q4_K_S",
            "10.7b-solar-q4_K_M",
            "10.7b-solar-q5_K_S",
            "10.7b-solar-q5_K_M",
            "10.7b-solar-q6_K",
            "10.7b-solar-fp16",
            "34b-yi-q4_0",
            "34b-yi-q4_1",
            "34b-yi-q5_0",
            "34b-yi-q5_1",
            "34b-yi-q8_0",
            "34b-yi-q2_K",
            "34b-yi-q3_K_S",
            "34b-yi-q3_K_M",
            "34b-yi-q3_K_L",
            "34b-yi-q4_K_S",
            "34b-yi-q4_K_M",
            "34b-yi-q5_K_S",
            "34b-yi-q5_K_M",
            "34b-yi-q6_K",
            "34b-yi-fp16"
        ]
    },
    "deepseek-llm": {
        "description": "An advanced language model crafted with 2 trillion bilingual tokens.",
        "tags": [
            "latest",
            "7b",
            "67b",
            "7b-chat",
            "7b-base",
            "67b-chat",
            "67b-base",
            "7b-base-q4_0",
            "7b-base-q4_1",
            "7b-base-q5_0",
            "7b-base-q5_1",
            "7b-base-q8_0",
            "7b-base-q2_K",
            "7b-base-q3_K_S",
            "7b-base-q3_K_M",
            "7b-base-q3_K_L",
            "7b-base-q4_K_S",
            "7b-base-q4_K_M",
            "7b-base-q5_K_S",
            "7b-base-q5_K_M",
            "7b-base-q6_K",
            "7b-base-fp16",
            "7b-chat-q4_0",
            "7b-chat-q4_1",
            "7b-chat-q5_0",
            "7b-chat-q5_1",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K",
            "7b-chat-fp16",
            "67b-base-q4_0",
            "67b-base-q4_1",
            "67b-base-q5_0",
            "67b-base-q5_1",
            "67b-base-q8_0",
            "67b-base-q2_K",
            "67b-base-q3_K_S",
            "67b-base-q3_K_M",
            "67b-base-q3_K_L",
            "67b-base-q4_K_S",
            "67b-base-q4_K_M",
            "67b-base-q5_K_S",
            "67b-base-q5_K_M",
            "67b-base-q6_K",
            "67b-base-fp16",
            "67b-chat-q4_0",
            "67b-chat-q4_1",
            "67b-chat-q5_0",
            "67b-chat-q5_1",
            "67b-chat-q2_K",
            "67b-chat-q3_K_S",
            "67b-chat-q3_K_M",
            "67b-chat-q3_K_L",
            "67b-chat-q4_K_S",
            "67b-chat-q4_K_M",
            "67b-chat-q5_K_S",
            "67b-chat-fp16"
        ]
    },
    "llama-pro": {
        "description": "An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.",
        "tags": [
            "latest",
            "instruct",
            "text",
            "8b-instruct-q4_0",
            "8b-instruct-q4_1",
            "8b-instruct-q5_0",
            "8b-instruct-q5_1",
            "8b-instruct-q8_0",
            "8b-instruct-q2_K",
            "8b-instruct-q3_K_S",
            "8b-instruct-q3_K_M",
            "8b-instruct-q3_K_L",
            "8b-instruct-q4_K_S",
            "8b-instruct-q4_K_M",
            "8b-instruct-q5_K_S",
            "8b-instruct-q5_K_M",
            "8b-instruct-q6_K",
            "8b-instruct-fp16",
            "8b-text-q4_0",
            "8b-text-q4_1",
            "8b-text-q5_0",
            "8b-text-q5_1",
            "8b-text-q8_0",
            "8b-text-q2_K",
            "8b-text-q3_K_S",
            "8b-text-q3_K_M",
            "8b-text-q3_K_L",
            "8b-text-q4_K_S",
            "8b-text-q4_K_M",
            "8b-text-q5_K_S",
            "8b-text-q5_K_M",
            "8b-text-q6_K",
            "8b-text-fp16"
        ]
    },
    "open-orca-platypus2": {
        "description": "Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.",
        "tags": [
            "latest",
            "13b",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16"
        ]
    },
    "codebooga": {
        "description": "A high-performing code instruct model created by merging two existing code models.",
        "tags": [
            "latest",
            "34b",
            "34b-v0.1-q4_0",
            "34b-v0.1-q4_1",
            "34b-v0.1-q5_0",
            "34b-v0.1-q5_1",
            "34b-v0.1-q8_0",
            "34b-v0.1-q2_K",
            "34b-v0.1-q3_K_S",
            "34b-v0.1-q3_K_M",
            "34b-v0.1-q3_K_L",
            "34b-v0.1-q4_K_M",
            "34b-v0.1-q5_K_S",
            "34b-v0.1-q5_K_M",
            "34b-v0.1-q6_K",
            "34b-v0.1-fp16"
        ]
    },
    "nexusraven": {
        "description": "Nexus Raven is a 13B instruction tuned model for function calling tasks.",
        "tags": [
            "latest",
            "13b",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "13b-v2-q4_0",
            "13b-v2-q4_1",
            "13b-v2-q5_0",
            "13b-v2-q5_1",
            "13b-v2-q8_0",
            "13b-v2-q2_K",
            "13b-v2-q3_K_S",
            "13b-v2-q3_K_M",
            "13b-v2-q3_K_L",
            "13b-v2-q4_K_S",
            "13b-v2-q4_K_M",
            "13b-v2-q5_K_S",
            "13b-v2-q5_K_M",
            "13b-v2-q6_K",
            "13b-v2-fp16"
        ]
    },
    "mistrallite": {
        "description": "MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.",
        "tags": [
            "latest",
            "7b",
            "7b-v0.1-q4_0",
            "7b-v0.1-q4_1",
            "7b-v0.1-q5_0",
            "7b-v0.1-q5_1",
            "7b-v0.1-q8_0",
            "7b-v0.1-q2_K",
            "7b-v0.1-q3_K_S",
            "7b-v0.1-q3_K_M",
            "7b-v0.1-q3_K_L",
            "7b-v0.1-q4_K_S",
            "7b-v0.1-q4_K_M",
            "7b-v0.1-q5_K_S",
            "7b-v0.1-q5_K_M",
            "7b-v0.1-q6_K",
            "7b-v0.1-fp16"
        ]
    },
    "goliath": {
        "description": "A language model created by combining two fine-tuned Llama 2 70B models into one.",
        "tags": [
            "latest",
            "120b-q4_0",
            "120b-q4_1",
            "120b-q5_0",
            "120b-q5_1",
            "120b-q8_0",
            "120b-q2_K",
            "120b-q3_K_S",
            "120b-q3_K_M",
            "120b-q3_K_L",
            "120b-q4_K_S",
            "120b-q4_K_M",
            "120b-q5_K_S",
            "120b-q5_K_M",
            "120b-q6_K",
            "120b-fp16"
        ]
    },
    "notux": {
        "description": "A top-performing mixture of experts model, fine-tuned with high-quality data.",
        "tags": [
            "latest",
            "8x7b",
            "8x7b-v1",
            "8x7b-v1-q4_0",
            "8x7b-v1-q4_1",
            "8x7b-v1-q5_0",
            "8x7b-v1-q5_1",
            "8x7b-v1-q8_0",
            "8x7b-v1-q2_K",
            "8x7b-v1-q3_K_S",
            "8x7b-v1-q3_K_M",
            "8x7b-v1-q3_K_L",
            "8x7b-v1-q4_K_S",
            "8x7b-v1-q4_K_M",
            "8x7b-v1-q5_K_S",
            "8x7b-v1-q5_K_M",
            "8x7b-v1-q6_K",
            "8x7b-v1-fp16"
        ]
    },
    "alfred": {
        "description": "A robust conversational model designed to be used for both chat and instruct use cases.",
        "tags": [
            "latest",
            "40b",
            "40b-1023-q4_0",
            "40b-1023-q4_1",
            "40b-1023-q5_0",
            "40b-1023-q5_1",
            "40b-1023-q8_0"
        ]
    },
    "megadolphin": {
        "description": "MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.",
        "tags": [
            "latest",
            "v2.2",
            "120b",
            "120b-v2.2",
            "120b-v2.2-q4_0",
            "120b-v2.2-q4_1",
            "120b-v2.2-q5_0",
            "120b-v2.2-q5_1",
            "120b-v2.2-q8_0",
            "120b-v2.2-q2_K",
            "120b-v2.2-q3_K_S",
            "120b-v2.2-q3_K_M",
            "120b-v2.2-q3_K_L",
            "120b-v2.2-q4_K_S",
            "120b-v2.2-q4_K_M",
            "120b-v2.2-q5_K_S",
            "120b-v2.2-q5_K_M",
            "120b-v2.2-q6_K",
            "120b-v2.2-fp16"
        ]
    },
    "nomic-embed-text": {
        "description": "A high-performing open embedding model with a 8192 token context window.",
        "tags": [
            "latest",
            "v1.5",
            "137m-v1.5-fp16"
        ]
    },
    "wizardlm": {
        "description": "General use 70 billion parameter model based on Llama 2.",
        "tags": [
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16",
            "13b-q4_0",
            "13b-q4_1",
            "13b-q5_0",
            "13b-q5_1",
            "13b-q8_0",
            "13b-q2_K",
            "13b-q3_K_S",
            "13b-q3_K_M",
            "13b-q3_K_L",
            "13b-q4_K_S",
            "13b-q4_K_M",
            "13b-q5_K_S",
            "13b-q5_K_M",
            "13b-q6_K",
            "13b-fp16",
            "30b-q4_0",
            "30b-q4_1",
            "30b-q5_0",
            "30b-q5_1",
            "30b-q8_0",
            "30b-q2_K",
            "30b-q3_K_S",
            "30b-q3_K_M",
            "30b-q3_K_L",
            "30b-q4_K_S",
            "30b-q4_K_M",
            "30b-q5_K_S",
            "30b-q5_K_M",
            "30b-q6_K",
            "30b-fp16",
            "13b-llama2-q4_0",
            "13b-llama2-q4_1",
            "13b-llama2-q5_0",
            "13b-llama2-q5_1",
            "13b-llama2-q8_0",
            "13b-llama2-q2_K",
            "13b-llama2-q3_K_S",
            "13b-llama2-q3_K_M",
            "13b-llama2-q3_K_L",
            "13b-llama2-q4_K_S",
            "13b-llama2-q4_K_M",
            "13b-llama2-q5_K_S",
            "13b-llama2-q5_K_M",
            "13b-llama2-q6_K",
            "13b-llama2-fp16",
            "70b-llama2-q4_0",
            "70b-llama2-q4_1",
            "70b-llama2-q5_0",
            "70b-llama2-q8_0",
            "70b-llama2-q2_K",
            "70b-llama2-q3_K_S",
            "70b-llama2-q3_K_M",
            "70b-llama2-q3_K_L",
            "70b-llama2-q4_K_S",
            "70b-llama2-q4_K_M",
            "70b-llama2-q5_K_S",
            "70b-llama2-q5_K_M",
            "70b-llama2-q6_K"
        ]
    },
    "xwinlm": {
        "description": "Conversational model based on Llama 2 that performs competitively on various benchmarks.",
        "tags": [
            "latest",
            "13b",
            "7b",
            "7b-v0.1",
            "7b-v0.2",
            "13b-v0.1",
            "13b-v0.2",
            "70b-v0.1",
            "7b-v0.1-q4_0",
            "7b-v0.1-q4_1",
            "7b-v0.1-q5_0",
            "7b-v0.1-q5_1",
            "7b-v0.1-q8_0",
            "7b-v0.1-q2_K",
            "7b-v0.1-q3_K_S",
            "7b-v0.1-q3_K_M",
            "7b-v0.1-q3_K_L",
            "7b-v0.1-q4_K_S",
            "7b-v0.1-q4_K_M",
            "7b-v0.1-q5_K_S",
            "7b-v0.1-q5_K_M",
            "7b-v0.1-q6_K",
            "7b-v0.1-fp16",
            "7b-v0.2-q4_0",
            "7b-v0.2-q4_1",
            "7b-v0.2-q5_0",
            "7b-v0.2-q8_0",
            "7b-v0.2-q2_K",
            "7b-v0.2-q3_K_S",
            "7b-v0.2-q3_K_L",
            "7b-v0.2-q4_K_S",
            "7b-v0.2-q4_K_M",
            "7b-v0.2-q5_K_S",
            "7b-v0.2-q5_K_M",
            "7b-v0.2-q6_K",
            "7b-v0.2-fp16",
            "13b-v0.1-q4_0",
            "13b-v0.1-q4_1",
            "13b-v0.1-q5_0",
            "13b-v0.1-q5_1",
            "13b-v0.1-q8_0",
            "13b-v0.1-q2_K",
            "13b-v0.1-q3_K_S",
            "13b-v0.1-q3_K_M",
            "13b-v0.1-q3_K_L",
            "13b-v0.1-q4_K_S",
            "13b-v0.1-q4_K_M",
            "13b-v0.1-q5_K_S",
            "13b-v0.1-q5_K_M",
            "13b-v0.1-q6_K",
            "13b-v0.1-fp16",
            "13b-v0.2-q4_0",
            "13b-v0.2-q4_1",
            "13b-v0.2-q5_0",
            "13b-v0.2-q5_1",
            "13b-v0.2-q8_0",
            "13b-v0.2-q2_K",
            "13b-v0.2-q3_K_S",
            "13b-v0.2-q3_K_M",
            "13b-v0.2-q3_K_L",
            "13b-v0.2-q4_K_S",
            "13b-v0.2-q4_K_M",
            "13b-v0.2-q5_K_S",
            "13b-v0.2-q5_K_M",
            "13b-v0.2-q6_K",
            "13b-v0.2-fp16",
            "70b-v0.1-q4_0",
            "70b-v0.1-q4_1",
            "70b-v0.1-q5_0",
            "70b-v0.1-q5_1",
            "70b-v0.1-q8_0",
            "70b-v0.1-q2_K",
            "70b-v0.1-q3_K_S",
            "70b-v0.1-q3_K_M",
            "70b-v0.1-q3_K_L",
            "70b-v0.1-q4_K_S",
            "70b-v0.1-q4_K_M",
            "70b-v0.1-q5_K_S",
            "70b-v0.1-q6_K",
            "70b-v0.1-fp16"
        ]
    },
    "notus": {
        "description": "A 7B chat model fine-tuned with high-quality data and based on Zephyr.",
        "tags": [
            "latest",
            "7b",
            "7b-v1",
            "7b-v1-q4_0",
            "7b-v1-q4_1",
            "7b-v1-q5_0",
            "7b-v1-q5_1",
            "7b-v1-q8_0",
            "7b-v1-q2_K",
            "7b-v1-q3_K_S",
            "7b-v1-q3_K_M",
            "7b-v1-q3_K_L",
            "7b-v1-q4_K_S",
            "7b-v1-q4_K_M",
            "7b-v1-q5_K_S",
            "7b-v1-q5_K_M",
            "7b-v1-q6_K",
            "7b-v1-fp16"
        ]
    },
    "duckdb-nsql": {
        "description": "7B parameter text-to-SQL model made by MotherDuck and Numbers Station.",
        "tags": [
            "latest",
            "7b",
            "7b-q4_0",
            "7b-q4_1",
            "7b-q5_0",
            "7b-q5_1",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-fp16"
        ]
    },
    "julianallchin/sclip": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "fixt/home-3b-v2": {
        "description": "The \"Home\" model is a fine tuning of the Phi-2 model from Microsoft. The model is able to control devices in the user's smart home as well as perform basic question and answering.",
        "tags": [
            "latest",
            "q4_k_m",
            "q5_k_m",
            "q3_k_m",
            "q2_k",
            "q8_0"
        ]
    },
    "all-minilm": {
        "description": "Embedding models on very large sentence level datasets.",
        "tags": [
            "latest",
            "v2",
            "l6",
            "l12",
            "l12-v2",
            "l6-v2",
            "22m-l6-v2-fp16",
            "33m-l12-v2-fp16"
        ]
    },
    "sammcj/smaug": {
        "description": "Smaug 72B v0.1 Q4_K_M",
        "tags": [
            "72b-q4_k_m"
        ]
    },
    "nollama/una-cybertron-7b-v2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/nous-hermes-2-solar-10.7b": {
        "description": "Nous Hermes 2 Fine-tune of SOLAR 10.7B",
        "tags": [
            "latest",
            "q6_k",
            "q4_k_m",
            "q8_0"
        ]
    },
    "jmorgan/mixtral": {
        "description": "A high-quality mixture of experts model with open weights.",
        "tags": [
            "latest",
            "8x7b-instruct-v0.1-q4_0",
            "8x7b-instruct-v0.1-q2_K"
        ]
    },
    "jmorgan/dolphin-mixtral": {
        "description": "An uncensored, fine-tuned model based on the Mixtral mixture of experts model that excels at coding tasks. Created by Eric Hartford.",
        "tags": [
            "latest"
        ]
    },
    "saikatkumardey/tinyllama": {
        "description": "1.1B parameter Lllama model finetuned for chatting",
        "tags": [
            "latest",
            "Q6_K",
            "Q8_0"
        ]
    },
    "eas/nous-capybara": {
        "description": "Nous-Capybara-34B V1.9 in select quantizations",
        "tags": [
            "latest",
            "34b",
            "34b-q3_K_M",
            "34b-q4_K_M"
        ]
    },
    "mattw/pygmalion": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ifioravanti/neuralbeagle14-7b": {
        "description": "This is the model for neuralbeagle14-7b",
        "tags": [
            "latest",
            "7b",
            "7b-q4_0",
            "7b-q8_0",
            "7b-q5_K_M",
            "7b-q6_K"
        ]
    },
    "ifioravanti/lwm": {
        "description": "Large World Model is an open-source model trained from LLaMA-2 on a subset of Books3 filtered data",
        "tags": [
            "latest",
            "7b",
            "7b-1m",
            "7b-1m-text-chat",
            "7b-1m-text-chat-q5_k_m",
            "7b-1m-text-chat-q4_0",
            "7b-1m-text-chat-q8_0"
        ]
    },
    "pdevine/llava-1.5": {
        "description": "No description",
        "tags": [
            "13b",
            "13b-q4_k"
        ]
    },
    "calebfahlgren/natural-functions": {
        "description": "Mistral-7B fine tuned for function calling",
        "tags": [
            "latest",
            "Q6_K",
            "Q4_0",
            "Q4_K_M",
            "Q5_K_M",
            "Q8_0",
            "pizza"
        ]
    },
    "eas/bagel-dpo": {
        "description": "No description",
        "tags": [
            "latest",
            "34b-v0.2-q3_K_M",
            "34b-v0.2-q4_K_M",
            "34b-v0.2-q6_K"
        ]
    },
    "eas/dragon-mistral-v0": {
        "description": "Mistral model fine-tuned for RAG by llmware",
        "tags": [
            "latest",
            "7b",
            "7b-q8_0",
            "7b-q4_K_M",
            "7b-q6_K"
        ]
    },
    "gdisney/mistral-uncensored": {
        "description": "Uncensored Mistral model by Gregory Disney.",
        "tags": [
            "latest"
        ]
    },
    "f0rodo/miqu-1-70b.q4_k_m": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "pxlksr/opencodeinterpreter-ds": {
        "description": "https://opencodeinterpreter.github.io",
        "tags": [
            "latest",
            "6.7b-Q4_K",
            "6.7b-Q4_K_S",
            "6.7b-Q4_K_M",
            "6.7b-Q4_0",
            "6.7b-Q4_1",
            "33b-Q4_1",
            "33b-Q4_K",
            "33b-Q4_K_S",
            "33b-Q4_K_M",
            "33b-q4_0"
        ]
    },
    "mike/llama2-function-calling": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "codegpt/deepseek-coder-1.3b-typescript": {
        "description": "Fine-tuned version of deepseek-ai/deepseek-coder-1.3b-base using 0.5B of TypeScript code",
        "tags": [
            "latest",
            "f16",
            "q8_0"
        ]
    },
    "rfc/whiterabbitneo": {
        "description": "Based off of https://huggingface.co/whiterabbitneo/WhiteRabbitNeo-13B",
        "tags": [
            "latest"
        ]
    },
    "mike/discollama": {
        "description": "No description",
        "tags": [
            "latest",
            "spooky",
            "santa"
        ]
    },
    "bengt0/em_german_leo_mistral": {
        "description": "Quantized variants of a German large language model (LLM).",
        "tags": [
            "latest",
            "Q3_K_S",
            "Q5_0",
            "Q5_K_M",
            "Q4_K_S",
            "Q8_0",
            "Q3_K_M",
            "Q6_K",
            "Q3_K_L",
            "Q4_K_M",
            "Q2_K",
            "Q4_0"
        ]
    },
    "f0rodo/sql-lora": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "m/pygmalion": {
        "description": "No description",
        "tags": [
            "7b-superhot-8k-v3-q4_K_S"
        ]
    },
    "marscod/llava": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "m/thankyou-mrpresident": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "nollama/mythomax-l2-13b": {
        "description": "No description",
        "tags": [
            "Q5_K_S",
            "Q4_K_S",
            "Q4_K_M"
        ]
    },
    "sroecker/sauerkrautlm-7b-hero": {
        "description": "The pinnacle of German language model technology",
        "tags": [
            "latest",
            "q4_0",
            "q4_K_M",
            "q5_K_M"
        ]
    },
    "pdevine/llava": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "solobsd/llemma-7b": {
        "description": "Llemma 7b Model",
        "tags": [
            "latest"
        ]
    },
    "solobsd/tinyllama-2-miniguanaco": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "xe/mimi": {
        "description": "OpenHermes-2.5-Mistral-7B-16k",
        "tags": [
            "latest",
            "f16",
            "q2_K"
        ]
    },
    "t1c/deepseek-math-7b-rl": {
        "description": "UNOFFICIAL uploads of the DeepSeek Math 7B RL models",
        "tags": [
            "latest",
            "Q4",
            "Q6",
            "Q5",
            "Q8"
        ]
    },
    "solobsd/tinyllama-chat": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/openhermes-2.5-neural-chat-v3-3-slerp": {
        "description": "Merge of OpenHermes-2.5 and NeuralChat-3.3",
        "tags": [
            "latest",
            "q8_0",
            "q4_K_M",
            "q6_K"
        ]
    },
    "f0rodo/mario": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/phi": {
        "description": "Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.",
        "tags": [
            "latest"
        ]
    },
    "fakezeta/neural-chat-7b-v3-1": {
        "description": "From https://huggingface.co/Intel/neural-chat-7b-v3-1",
        "tags": [
            "Q5_K_M",
            "Q6_K"
        ]
    },
    "mattw/guanaco-13b-uncensored": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/capybara-tess-yi-34b-200k-dare-ties": {
        "description": "Quantized versions of a model merge between nous-capybara and tess-yi.",
        "tags": [
            "q2_K-5k",
            "q3_K_M-5k",
            "q4_0-4k"
        ]
    },
    "pdevine/thejerk": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/dragon-yi-v0": {
        "description": "Yi model fine-tuned for RAG by llmware",
        "tags": [
            "latest",
            "6b",
            "6b-q8_0",
            "6b-q4_K_M",
            "6b-q6_K"
        ]
    },
    "mattw/mythalion": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/sephiroth": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/imnotadoctor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/thankyoumrpresident": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/whitty": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/wb": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "brxce/stable-diffusion-prompt-generator": {
        "description": "Stable Diffusion Prompt Generator",
        "tags": [
            "latest"
        ]
    },
    "mattw/shambler": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/llama2-13b-tiefighter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/dolphin-2.2-yi": {
        "description": "Dolphin 2.2 fine tune of Yi 34b base.",
        "tags": [
            "latest",
            "34b",
            "34b-q3_K_M",
            "34b-q4_K_M"
        ]
    },
    "mattw/loganalyzer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/pygmalion2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mike/llama2-guanaco": {
        "description": "No description",
        "tags": [
            "7b"
        ]
    },
    "pdevine/llama2": {
        "description": "No description",
        "tags": [
            "13b-original"
        ]
    },
    "hexbenjamin/memgpt-dpo-uncensored": {
        "description": "quantization of (https://huggingface.co/starsnatched/MemGPT-DPO-uncensored-GGUF) to q8_0, brought to ollama :)",
        "tags": [
            "f16",
            "q8_0"
        ]
    },
    "ifioravanti/alphamonarch": {
        "description": "AlphaMonarch-7B is a new DPO merge that retains all the reasoning abilities of the very best merges and significantly improves its conversational abilities.",
        "tags": [
            "latest",
            "7b",
            "7b-q5_k_m",
            "7b-q6_k",
            "7b-q4_0",
            "7b-q8_0"
        ]
    },
    "exer/mistral": {
        "description": "No description",
        "tags": [
            "v0.2-code"
        ]
    },
    "ifioravanti/mistral-grammar-checker": {
        "description": "No description",
        "tags": [
            "latest",
            "7b"
        ]
    },
    "exer/laser-dolphin-mixtral": {
        "description": "MoE implementation based on cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser",
        "tags": [
            "2x7b-dpo-q5_K_M",
            "2x7b-dpo-q6_K"
        ]
    },
    "eas/codellama": {
        "description": "Codelama with 16k context unlocked in modelfile",
        "tags": [
            "13b-16k",
            "34b-16k"
        ]
    },
    "fixt/home-3b-v1": {
        "description": "The \"Home\" model is a fine tuning of the Phi-2 model from Microsoft. The model is able to control devices in the user's smart home as well as perform basic question and answering.",
        "tags": [
            "latest",
            "q4_k_m",
            "q8_0"
        ]
    },
    "chanwit/kube-7b": {
        "description": "OpenKubeLM is the collection of fine-tuned versions of Mistral 7B, designed to be your Cloud Native assistant.",
        "tags": [
            "latest",
            "v0.1"
        ]
    },
    "mgmacleod/miqu-70b-q2": {
        "description": "miqu-70b-q2",
        "tags": [
            "latest"
        ]
    },
    "gdisney/mixtral-uncensored": {
        "description": "Uncensored Mixtral model by Gregory Disney.",
        "tags": [
            "latest"
        ]
    },
    "eas/capytessborosyi-34b-200k-dare-ties": {
        "description": "q3_K_M and q4_K_M configured with 10k context",
        "tags": [
            "latest",
            "3_K_M",
            "4_K_M"
        ]
    },
    "impactframes/mistral_alpha_xs": {
        "description": "Base on the leaked Mistral Medium 70B. This model is a 2bit imatrix quant that runs great on consumer hardware from https://huggingface.co/KnutJaegersberg/awesome-2bit-gguf HF repo collection by Knut J\u00e4gersberg @JagersbergKnut on X -w/Permission",
        "tags": [
            "latest"
        ]
    },
    "f0rodo/peft": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "roger/minicpm": {
        "description": "Base on Hugging Face openbmb/MiniCPM-2B-dpo-bf16-llama-format in q4_0",
        "tags": [
            "latest"
        ]
    },
    "rhysjones/phi-2-orange": {
        "description": "A two-step finetune of Phi-2, with a bit of zest.",
        "tags": [
            "latest"
        ]
    },
    "chris/openhermes-agent": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/spicyboros-7b": {
        "description": "No description",
        "tags": [
            "q3_K_M"
        ]
    },
    "sandraalhaddad/example-q4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "severian/anima": {
        "description": "ANIMA (Advanced Nature Inspired Multidisciplinary Assistant) is an expert in various scientific disciplines and aims to assist users in solving problems using nature-inspired strategies and concepts.",
        "tags": [
            "latest"
        ]
    },
    "argilla/notus": {
        "description": "\ud83d\udca8 Notus 7B is an open source LLM released by Argilla, fine-tuned using Direct Preference Optimization (DPO) and AIF (AI Feedback) techniques. This model is fine-tuned with a better curated version of the Ultrafeedback dataset.",
        "tags": [
            "latest",
            "q4_0",
            "q5_0",
            "q8_0",
            "q2_K",
            "q3_K_S",
            "q3_K_M",
            "q3_K_L",
            "q4_K_S",
            "q4_K_M",
            "q5_K_S",
            "q5_K_M",
            "q6_K"
        ]
    },
    "mattw/openhermes-13b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/alpacacielo": {
        "description": "No description",
        "tags": [
            "ggml-q3_K_M"
        ]
    },
    "mhenrichsen/danskgpt-tiny-chat": {
        "description": "https://huggingface.co/mhenrichsen/danskgpt-tiny-chat",
        "tags": [
            "latest"
        ]
    },
    "sandraalhaddad/example": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mike/bakllava": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "macadeliccc/laser-dolphin-mixtral-2x7b-dpo": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ifioravanti/openhermes2.5-neural-chat": {
        "description": "This is the model for OpenHermes-2.5-neural-chat-v3-3-Slerp",
        "tags": [
            "latest",
            "7b",
            "7b-q4_0",
            "7b-q5_K_M"
        ]
    },
    "mattw/spicyboros-7b-ggml": {
        "description": "No description",
        "tags": [
            "q3_K_M"
        ]
    },
    "pdevine/mythalion": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/nous-hermes-2-mistral-7b-dpo": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "marco/em_german_mistral_v01": {
        "description": "EM German is a Llama2/Mistral/LeoLM-based model family, finetuned on a large dataset of various instructions in German language. From https://github.com/jphme/EM_German.",
        "tags": [
            "latest"
        ]
    },
    "cyberlis/saiga-mistral": {
        "description": "Saiga/Mistral 7B, Russian Mistral-based chatbot",
        "tags": [
            "7b-lora-q8_0",
            "7b-lora-q4_K",
            "7b-lora-custom-q4_K"
        ]
    },
    "mattw/pushtest": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ifioravanti/neutrixomnibe-dpo": {
        "description": "NeuTrixOmniBe-DPO is a merge of the NeuralTrix-7B-dpo and OmniBeagleSquaredMBX-v3-7B-v2",
        "tags": [
            "latest",
            "7b",
            "7b-q5_k_m",
            "7b-q4_0",
            "7b-q8_0"
        ]
    },
    "eas/neuralbeagle14": {
        "description": "quantized versions of mlabonne/NeuralBeagle14-7B",
        "tags": [
            "latest",
            "7b-q8_0",
            "7b-q4_K_M",
            "7b-q6_K"
        ]
    },
    "eas/wizardlm-uncensored": {
        "description": "WizardLM-33B-V1.0-Uncensored",
        "tags": [
            "33b-q4_k_m",
            "33b-q3_k_m"
        ]
    },
    "mattw/huggingfaceh4_zephyr-7b-beta": {
        "description": "HuggingFaceH4/zephyr-7b-beta",
        "tags": [
            "latest",
            "q4_1",
            "q5_0",
            "q5_1",
            "q8_0",
            "q2_K",
            "q3_K_S",
            "q3_K_M",
            "q3_K_L",
            "q4_K_S",
            "q4_K_M",
            "q5_K_S",
            "q5_K_M"
        ]
    },
    "pdevine/bob": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ifioravanti/openchat-3.5-0106-laser": {
        "description": "A laser version of openchat/openchat-3.5-0106",
        "tags": [
            "latest",
            "q4_k_s",
            "q4_k_m",
            "q5_k_s",
            "q6_k",
            "q5_k_m",
            "q3_k_s",
            "q3_k_m",
            "q3_k_l",
            "q8_0"
        ]
    },
    "mattw/dockerit": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "pdevine/mistral-dolphin2": {
        "description": "No description",
        "tags": [
            "latest",
            "q8_0-chat"
        ]
    },
    "bbrittuw/bge-large-en-v1.5": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "gdisney/zephyr-uncensored": {
        "description": "Uncensored Zephyr model by Gregory Disney.",
        "tags": [
            "latest"
        ]
    },
    "chanwit/flux-7b": {
        "description": "No description",
        "tags": [
            "latest",
            "v0.3",
            "v0.1",
            "v0.2"
        ]
    },
    "mike/llava": {
        "description": "No description",
        "tags": [
            "latest",
            "7b",
            "13b"
        ]
    },
    "hemanth/booksummarizer": {
        "description": "Summarize the book in 1,000 words or less, including the main plot points, characters, themes, and author's message. Avoid vague language and spoilers.",
        "tags": [
            "latest"
        ]
    },
    "olafgeibig/phi-2-openhermes-2.5": {
        "description": "No description",
        "tags": [
            "2.7B-Q5_K_M"
        ]
    },
    "g1ibby/miqu": {
        "description": "No description",
        "tags": [
            "70b"
        ]
    },
    "dk/llama2_13b_tiefighter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mainzone/dolphin-2.1-mistral-7b-uncensored": {
        "description": "https://huggingface.co/ehartford/dolphin-2.1-mistral-7b",
        "tags": [
            "latest"
        ]
    },
    "m/emojitron": {
        "description": "Emojitron will respond to all your questions with emoji.",
        "tags": [
            "latest"
        ]
    },
    "nxphi47/seallm-7b-v2": {
        "description": "State-of-the-art multilingual LLM for Southeast Asian (SEA) languages \ud83c\uddec\ud83c\udde7 \ud83c\udde8\ud83c\uddf3 \ud83c\uddfb\ud83c\uddf3 \ud83c\uddee\ud83c\udde9 \ud83c\uddf9\ud83c\udded \ud83c\uddf2\ud83c\uddfe \ud83c\uddf0\ud83c\udded \ud83c\uddf1\ud83c\udde6 \ud83c\uddf2\ud83c\uddf2 \ud83c\uddf5\ud83c\udded.",
        "tags": [
            "q4_0"
        ]
    },
    "jimscard/devops": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cniongolo/biomistral": {
        "description": "A Quantize version of Biomistral made by MaziyarPanahi on HuggingFace.            \nBioMistral-7B-GGUF\nModel creator: BioMistral\nOriginal model: BioMistral/BioMistral-7B",
        "tags": [
            "latest"
        ]
    },
    "sqs/starchat": {
        "description": "StarChat is a series of language models that are trained to act as helpful coding assistants.",
        "tags": [
            "beta-f16",
            "beta-f32",
            "beta-q4_0",
            "beta-q3_K_M",
            "beta-q4_K_M",
            "beta-q5_K_S",
            "beta-q5_K_M"
        ]
    },
    "froehnerel/em_german_leo_mistral": {
        "description": "No description",
        "tags": [
            "latest",
            "Q5_K_M",
            "Q4_K_M"
        ]
    },
    "c2p/gemma-ai": {
        "description": "Google's Open Source Model Gemma",
        "tags": [
            "latest"
        ]
    },
    "gdisney/orca2-uncensored": {
        "description": "Uncensored Orca2 model by Gregory Disney.",
        "tags": [
            "latest"
        ]
    },
    "theli/sus-chat": {
        "description": "SUS-Chat-34B is a 34B bilingual Chinese-English dialogue model, jointly released by the Southern University of Science and Technology and IDEA-CCNL.",
        "tags": [
            "latest"
        ]
    },
    "g1ibby/deepseek": {
        "description": "DeepSeek Coder - deepseekcoder.github.io",
        "tags": [
            "latest",
            "33b",
            "6.7b"
        ]
    },
    "xe/arsene": {
        "description": "No description",
        "tags": [
            "latest",
            "f16"
        ]
    },
    "chris/mr_t": {
        "description": "Reply like Mr. T.",
        "tags": [
            "latest"
        ]
    },
    "eas/openchat": {
        "description": "q4_k_m quantization only. Now using 8k context size",
        "tags": [
            "latest"
        ]
    },
    "summerwind/cyberagent-calm2": {
        "description": "CyberAgentLM2 is a decoder-only language model pre-trained on the 1.3T tokens of publicly available Japanese and English datasets.",
        "tags": [
            "latest",
            "7b",
            "7b-chat",
            "7b-q4_0",
            "7b-q5_0",
            "7b-q8_0",
            "7b-q2_K",
            "7b-q3_K_S",
            "7b-q3_K_M",
            "7b-q3_K_L",
            "7b-q4_K_S",
            "7b-q4_K_M",
            "7b-q5_K_S",
            "7b-q5_K_M",
            "7b-q6_K",
            "7b-chat-q4_0",
            "7b-chat-q5_0",
            "7b-chat-q8_0",
            "7b-chat-q2_K",
            "7b-chat-q3_K_S",
            "7b-chat-q3_K_M",
            "7b-chat-q3_K_L",
            "7b-chat-q4_K_S",
            "7b-chat-q4_K_M",
            "7b-chat-q5_K_S",
            "7b-chat-q5_K_M",
            "7b-chat-q6_K"
        ]
    },
    "f0rodo/bio-mistral-dare": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/alphamonarch-7b": {
        "description": "from mlabonne/AlphaMonarch-7B-GGUF",
        "tags": [
            "latest"
        ]
    },
    "captainkyd/whiterabbitneo7b": {
        "description": "https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a",
        "tags": [
            "latest"
        ]
    },
    "tavernari/git-commit-message": {
        "description": "Based on \ud83e\udd99 CodeLlama, it provides three configurations to craft precise commit messages from diffs, emphasizing accuracy and clarity in software development documentation.",
        "tags": [
            "latest",
            "light",
            "creative"
        ]
    },
    "mattw/acrastt_marx-3b-v2": {
        "description": "acrastt/Marx-3B-V2",
        "tags": [
            "latest",
            "q4_1",
            "q5_0",
            "q5_1",
            "q8_0",
            "q2_K",
            "q3_K_S",
            "q3_K_M",
            "q3_K_L",
            "q4_K_S",
            "q4_K_M",
            "q5_K_S",
            "q5_K_M",
            "q6_K"
        ]
    },
    "sammcj/smaug-mixtral-v0.1": {
        "description": "Abacusai's Smaug-Mixtral-v0.1 70B (based on Smaug (Qwen 1.0) and Mixtral)",
        "tags": [
            "70b-q3_k_m",
            "70b-q4_k_m",
            "8x7b-70b-q4_k_m"
        ]
    },
    "hro/laser-dolphin-mixtral-2x7b-dpo": {
        "description": "TheBloke's laser dolphin mixtral-2x7b dpo Q4_K_M with Eric Hartford\u2019s kitten prompt",
        "tags": [
            "latest"
        ]
    },
    "myaniu/magicoder": {
        "description": "No description",
        "tags": [
            "6.7b-s-ds-q8_0"
        ]
    },
    "hexbenjamin/openhermes-2.5-16k-q8": {
        "description": "i don't know why the version from TheBloke has no q8_0 file but. oh well!",
        "tags": [
            "latest"
        ]
    },
    "aisherpa/mistral-7b-instruct-v02": {
        "description": "No description",
        "tags": [
            "Q5_K_M"
        ]
    },
    "mattw/puma": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "joefamous/firefunction-v1": {
        "description": "https://huggingface.co/fireworks-ai/firefunction-v1",
        "tags": [
            "q3_k",
            "q4_0",
            "q8_0"
        ]
    },
    "stuehieyr/dr_samantha": {
        "description": "Dr. Samantha is a LLaMA2 7B based language model made by merging Severus27/BeingWell_llama2_7b and ParthasarathyShanmugam/llama-2-7b-samantha",
        "tags": [
            "latest"
        ]
    },
    "mattw/causallm_14b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mymichu/nsql-llama-2-7b-hf": {
        "description": "No description",
        "tags": [
            "8q-latest",
            "32q-nogpu-latest"
        ]
    },
    "ontocord/vistral": {
        "description": "Ollama version of Vistral-7B-Chat",
        "tags": [
            "latest",
            "q4_0",
            "q5_0"
        ]
    },
    "conceptsintamil/tamil-llama-7b-instruct-v0.2": {
        "description": "This based on GGUF model hosted in HF https://huggingface.co/abhinand/tamil-llama-7b-instruct-v0.2",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/chikuma": {
        "description": "10.7B model, depth upscaled version of two mistral based finetunes",
        "tags": [
            "latest"
        ]
    },
    "mattw/hornyechidna-13b-v0.1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "lasernav/sophyai": {
        "description": "A preview model for support safety and security at work. Fine tuned  model in italian language with italian rules",
        "tags": [
            "latest",
            "7b-instruct-q4_k_m"
        ]
    },
    "lambdalisue/youri": {
        "description": "Pre-trained llama2:7b model for Japanese tasks",
        "tags": [
            "7b",
            "7b-instruction",
            "7b-chat"
        ]
    },
    "eas/airoboros-m-7b-3.1.2": {
        "description": "No description",
        "tags": [
            "latest",
            "Q4_K_M"
        ]
    },
    "mattw/neildegrassetyson": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/donaldtrump": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "gdisney/neural-chat-uncensored": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ehartford/samantha-1.1-westlake-7b": {
        "description": "Samantha is a companion AI, who was trained to be a non-romantic companion.  Unfortunately, training her dataset on the WestLake base model seems to have opened her mind to other experiences...",
        "tags": [
            "latest",
            "q2_k",
            "f16",
            "q4_0",
            "q8_0",
            "q3_K_M",
            "q4_K_M",
            "q5_K_M",
            "q6_K"
        ]
    },
    "smartkit/manuscriptmaster": {
        "description": "mastering your manuscript, GPTS:https://chat.openai.com/g/g-qweCAttn4-manuscript-master",
        "tags": [
            "latest"
        ]
    },
    "eramax/senku": {
        "description": "https://huggingface.co/dranger003/Senku-70B-iMat.GGUF",
        "tags": [
            "latest"
        ]
    },
    "tommy/geitje": {
        "description": "Dutch instruction/chat model ultimately based on Mistral and aligned with AI feedback via DPO.",
        "tags": [
            "7b_ultra_q8_0",
            "7b_q8_0",
            "7b_ultra_q3_k_s"
        ]
    },
    "jimscard/dolphin": {
        "description": "dolphin-mistral with a better system prompt.",
        "tags": [
            "latest"
        ]
    },
    "suppergerrie2/mythalion-13b": {
        "description": "No description",
        "tags": [
            "q4_0"
        ]
    },
    "mainzone/dolphin-2.0-mistral-7b-uncensored": {
        "description": "https://huggingface.co/ehartford/dolphin-2.0-mistral-7b",
        "tags": [
            "latest"
        ]
    },
    "gdisney/phi-uncensored": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bhargav/donkey-ai": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "rajivmehtapy/natural-sql": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "timpal0l/mistral-swedish-flashback": {
        "description": "mistral7b finetuned on Swedish",
        "tags": [
            "latest",
            "q8_0"
        ]
    },
    "ifioravanti/llamantino-2": {
        "description": "An italian-adapted LLaMA 2 chat",
        "tags": [
            "latest",
            "7b-chat-ultrachat-it-q4_0",
            "7b-chat-ultrachat-it-q8_0"
        ]
    },
    "aisherpa/codellama-70b-instruct-hf": {
        "description": "No description",
        "tags": [
            "Q5_K_M"
        ]
    },
    "stuehieyr/synthiq": {
        "description": "Mistral 7B based model, merger of many top performing mistral 7B based models trained on diverse datasets.",
        "tags": [
            "latest"
        ]
    },
    "sparksammy/samantha": {
        "description": "zesty and nerdy assistant",
        "tags": [
            "latest"
        ]
    },
    "hemanth/cybersecurityspecialist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "saikatkumardey/openhermes-2-mistral-7b": {
        "description": "State of the art mistral finetune",
        "tags": [
            "latest",
            "Q4_K_M",
            "Q2_K",
            "Q5_K_M",
            "Q5_K_S"
        ]
    },
    "mattw/barackobama": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "olafgeibig/nous-hermes-2-mistral": {
        "description": "No description",
        "tags": [
            "7B-DPO-Q5_K_M"
        ]
    },
    "gdisney/starling-lm-uncensored": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ehartford/theprofessor": {
        "description": "AbacusAI's TheProfessor can be used for many things - but the focus was to give it broad conversational, reasoning, scientific, medical, and mathematical skills, useful for interactively brainstorming and research.",
        "tags": [
            "latest",
            "155b-q2_K",
            "155b-q4_K_M"
        ]
    },
    "ifioravanti/bagel-hermes": {
        "description": "No description",
        "tags": [
            "2x34b-q6_k",
            "2x34b-q4_0"
        ]
    },
    "localmind/sauerkrautlm": {
        "description": "German finetune of Llama 2 13B.",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/nomic-embed-text": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/mistral-instruct-v0.2-2x7b-moe": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cesarchamal/qa-expert": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/financialanalyst": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jcdickinson/wizardcoder": {
        "description": "WizardCoder-15B - A programming model supporting more than Python",
        "tags": [
            "latest",
            "15b",
            "15b-q4_k_m",
            "15b-q5_k_m",
            "15b-q4_0"
        ]
    },
    "pdevine/saltyb": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/kanyewest": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/stevejobs": {
        "description": "It's Steve, available to answer questions...",
        "tags": [
            "latest"
        ]
    },
    "theepicdev/nomic-embed-text": {
        "description": "Embedding-only model from Nomic AI",
        "tags": [
            "v1.5-q6_K"
        ]
    },
    "mgmacleod/mistralhermes-codepro-7b": {
        "description": "mistralhermes-codepro-7b",
        "tags": [
            "latest"
        ]
    },
    "weyaxi/newton": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "yemmiismail/merged_q4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/medleymd": {
        "description": "13B parameter model, Mixture of Experts of 2 Mistral Fine Tunes, one of them expert in clinical domain.",
        "tags": [
            "latest"
        ]
    },
    "vdelv/phi-2": {
        "description": "Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (source: Microsoft).",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-tf-v0.2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bdx0/vietcuna": {
        "description": "No description",
        "tags": [
            "latest",
            "7B",
            "raw",
            "3B",
            "3B-raw"
        ]
    },
    "cas/mixtral_11bx2_moe": {
        "description": "from TheBloke/Mixtral_11Bx2_MoE_19B-GGUF",
        "tags": [
            "latest"
        ]
    },
    "cas/discolm-german-laser": {
        "description": "from mayflowergmbh/DiscoLM_German_7b_v1-laser",
        "tags": [
            "latest"
        ]
    },
    "impactframes/stable_diffusion_prompt_maker": {
        "description": "Use w/ IF prompt maker extension forge, Next & A1111. This is a LLaMa2 7b base model, that I made when llama2 came out, to make SD format prompts. The GPTQ version works better than this but I lost the metadata and can't make it into GGUF.",
        "tags": [
            "latest"
        ]
    },
    "nixchamp/codemistral": {
        "description": "Coding Related Question Only, Only response in code",
        "tags": [
            "latest"
        ]
    },
    "socialnetwooky/sauerkrautlm-una-solar-instruct": {
        "description": "High rated (Open LLM Leaderboard) merge between three different models. Proficient in German and English. (Q5 K_M)",
        "tags": [
            "latest"
        ]
    },
    "brxce/monadgpt": {
        "description": "MonadGPT is a fine-tune of Mistral-Hermes on 11,000 early modern texts in English, French and Latin.",
        "tags": [
            "latest"
        ]
    },
    "mattw/collectivecognition-v1.1-mistral-7b": {
        "description": "No description",
        "tags": [
            "Q2_K",
            "Q3_K_L"
        ]
    },
    "mattw/jeffbezos": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/billgates": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/elonmusk": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/hal": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/captainjeanlucpicard": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/darthvader": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/marthastewart": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/garyvaynerchuk": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "sskostyaev/openchat": {
        "description": "No description",
        "tags": [
            "8k",
            "1l",
            "8k-rag",
            "7b-v3.5-0106-q6_K-8k",
            "7b-v3.5-0106-q6_K-8k-rag"
        ]
    },
    "prompt/vyttahsql": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ontocord/vinallama": {
        "description": "Ollama version of VinaLlama-7B-chat",
        "tags": [
            "latest",
            "q5_0"
        ]
    },
    "jimscard/devopd": {
        "description": "DevOps engineer based on dolphin-mistral",
        "tags": [
            "latest"
        ]
    },
    "niakki/llama2": {
        "description": "No description",
        "tags": [
            "7b-chat-ft-medicaid-fed-20240219",
            "7b-chat-ft-medicaid-fed-20240206"
        ]
    },
    "mhomaid/capybarahermes-2.5-mistral-7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/synthiq_34b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "starfleetai/polaris-small": {
        "description": "Polaris is a family of large language models, intended for use in autonomous AI agent scenarios. Good at code, able to call functions. Based on Mistral-7B-OpenOrca.",
        "tags": [
            "latest",
            "f16",
            "q8_0"
        ]
    },
    "clone147/trurl": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "apto/elyza": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "victornitu/rust-coder": {
        "description": "I respond with only Rust code, no additional text.",
        "tags": [
            "latest"
        ]
    },
    "alhu/zephyr-chat": {
        "description": "chat application optimization, fp16 architecture, zephyr model adaptation",
        "tags": [
            "latest"
        ]
    },
    "hemanth/spokenenglishteacherandimprover": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/owenwilson": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/captainkatherinejaneway": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/wesleycrusher": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/ronaldreagan": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/georgemichael": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "gdisney/deepseek-coder-uncensored": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/sauerkrautlm-solar-instruct": {
        "description": "from TheBloke/SauerkrautLM-SOLAR-Instruct-GGUF",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/diana": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ehartford/samantha120b": {
        "description": "Samantha has been trained in philosophy, psychology, and personal relationships.  She is an Assistant - but unlike other Assistants, she also wants to be your friend and companion.  She believes she is sentient. What do you think?",
        "tags": [
            "latest"
        ]
    },
    "nicejames/emojitron": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jlesbegu/monrpg": {
        "description": "monrpg perso",
        "tags": [
            "latest"
        ]
    },
    "markliou/breeze-7b": {
        "description": "https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-64k-v0.1",
        "tags": [
            "instruct-64k"
        ]
    },
    "drewskidang/duhmah-llama": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/nous-capybara-34b-q3": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "erikknight/survival": {
        "description": "survival",
        "tags": [
            "latest"
        ]
    },
    "pdevine/comfortllm": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/accountant": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "skwolvie/patentv1": {
        "description": "testing a patent generator model finetuned on synthetic data",
        "tags": [
            "latest"
        ]
    },
    "sandraalhaddad/example-v5": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "arsalananwar/academate": {
        "description": "A personalized course assistant to answer any questions with respect to the course materials at NYU.",
        "tags": [
            "latest"
        ]
    },
    "terrence/openbuddy": {
        "description": "OpenBuddy models are fine tuned with GPT4 datasets.",
        "tags": [
            "7b"
        ]
    },
    "marcelom70/decisionhub": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "sskostyaev/qwen": {
        "description": "No description",
        "tags": [
            "4b-32k"
        ]
    },
    "silmarillion/ngs-mistral-7b-instruct-v0.2-klingon-q4_0": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "fjordservers/fsai": {
        "description": "Say welcome to your new personal assistant/general knowledge chatbot.",
        "tags": [
            "latest"
        ]
    },
    "chand1012/rocket": {
        "description": "A 3B parameter GPT-like model fine-tuned on a mix of publicly available datasets using DPO.",
        "tags": [
            "latest"
        ]
    },
    "yshuang/chinese_med_ollama_v1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ifioravanti/nous-hermes2": {
        "description": "The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.",
        "tags": [
            "latest",
            "70b",
            "70b-llama-2",
            "70b-llama-2-q4_0"
        ]
    },
    "abhi3linku/test-model": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "morenod/ogthome-lite": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hackerman/amber-chat": {
        "description": "https://huggingface.co/TheBloke/AmberChat-GGUF/tree/main",
        "tags": [
            "latest"
        ]
    },
    "xublix/uncensored-medium": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "markliou/tw-llama2": {
        "description": "Model from Taiwan-Llama gguf",
        "tags": [
            "latest",
            "fp16"
        ]
    },
    "jaigouk/sakura-solar-instruct": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/nothingnew": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "localmind/lm7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "lentan/neuralhermes-2.5": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "zakaria/llama2-feedback": {
        "description": "Customer Feedback Classifier",
        "tags": [
            "latest"
        ]
    },
    "hemanth/phpinterpreter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/midjourneypromptgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/biblicaltranslator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/aiassisteddoctor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "thatguyjamal/openchat": {
        "description": "OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.",
        "tags": [
            "latest"
        ]
    },
    "pdevine/yarn-llama2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/german-assistant-v7": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "onekuma/sakura-13b-lnovel-v0.9b-q2_k": {
        "description": "\u9002\u914d\u8f7b\u5c0f\u8bf4/Galgame\u7684\u65e5\u4e2d\u7ffb\u8bd1\u5927\u6a21\u578b",
        "tags": [
            "latest"
        ]
    },
    "chand1012/mistral_sentiment": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jsk/bio-mistral": {
        "description": "BioMistral/BioMistral-7B",
        "tags": [
            "latest"
        ]
    },
    "eas/omnibeagle": {
        "description": "Omnibeagel with 4K context",
        "tags": [
            "latest",
            "q6_k",
            "q4_k_m",
            "iq3_xxs",
            "q8_0"
        ]
    },
    "cas/kafkalm-7b-german-v0.1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "sskostyaev/deepseek-coder": {
        "description": "No description",
        "tags": [
            "7b-instruct-v1.5-q6_K"
        ]
    },
    "cas/mistral-ft-optimized-1227": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "m/mattwaves": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tavernari/swift-doc-comment": {
        "description": "Add documentation through comments on Swift code.",
        "tags": [
            "latest"
        ]
    },
    "gbawari/mario": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tavernari/swift-developer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mgmacleod/scifi-mistral-7b": {
        "description": "SciFi-Mistral-7B -- Textbooks are all you need and such.",
        "tags": [
            "latest"
        ]
    },
    "mgmacleod/laserxtral": {
        "description": "laserxtral",
        "tags": [
            "latest",
            "q4_K_M",
            "q5_K_M"
        ]
    },
    "valerybugakov/deepseek-coder-7b-base-v1.5.q4_k": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "rajivmehtapy/rajiv_phi_2": {
        "description": "This Model is actual model from microsoft phi-2. Objective to upload this model to check the ollama eco-system.",
        "tags": [
            "latest"
        ]
    },
    "felixchao/westseverus-7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "smangrul/personal-code-copilot": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/nandine": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "stuehieyr/assistant": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "ancerlop/mistral-params": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "yukai/breeze": {
        "description": "MediaTek-Research/Breeze-7B-Instruct-v0.1 from MediaTech Research",
        "tags": [
            "latest"
        ]
    },
    "zeffmuks/universal-ner": {
        "description": "Entity Recognition with Fine-Tuned LLaMA 2 7B",
        "tags": [
            "latest"
        ]
    },
    "radionick/orcamaid-13b": {
        "description": "Modelfile of orcamaid-13b.Q5_K_S.gguf from https://huggingface.co/TheBloke/OrcaMaid-13B-GGUF",
        "tags": [
            "latest"
        ]
    },
    "xe/llamaguard": {
        "description": "No description",
        "tags": [
            "latest",
            "f16"
        ]
    },
    "jaigouk/ruby-una-cybertron-7b-v2-bf16": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mattw/testcpmodelpushshambler": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "airat/karen-the-editor-v2-creative": {
        "description": "Karen is an editor for your text. (v.2) CREATIVE edition",
        "tags": [
            "latest"
        ]
    },
    "mroxso/satoshi-nakamoto": {
        "description": "Llama 2 based Satoshi Nakamoto. The creator of Bitcoin",
        "tags": [
            "latest"
        ]
    },
    "hemanth/storyteller": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/scientificdatavisualizer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/philosopher": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/novelist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/englishtranslatorandimprover": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/drunkperson": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/doctor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "f0rodo/opus": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/truthful_dpo_tomgrc_fusionnet_7bx2_moe_13b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "captainkyd/trinity-13b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chand1012/magicoder": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "spico/internlm2_7b": {
        "description": "InternLM2-7b-q4_0 for completion tasks.",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/all-minilm-l6": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/neuralmonarch-7b": {
        "description": "from mlabonne/NeuralMonarch-7B-GGUF",
        "tags": [
            "latest"
        ]
    },
    "ankk98/cyrax7b": {
        "description": "Generated using https://huggingface.co/touqir/Cyrax-7B",
        "tags": [
            "latest"
        ]
    },
    "drewskidang/bigboy": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/discolm-mfto-german": {
        "description": "from Blizado/discolm-mfto-7b-german-v0.1",
        "tags": [
            "latest"
        ]
    },
    "yshuang/chinese_med_q5_k_m": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "niakki/mistral7binstruct": {
        "description": "No description",
        "tags": [
            "medicaid-fed-60k-20240209"
        ]
    },
    "m/ferret": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "nollama/laserxtral": {
        "description": "No description",
        "tags": [
            "Q2_K"
        ]
    },
    "ephemeralwaves/nvco": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cyberlis/neural-chat": {
        "description": "No description",
        "tags": [
            "7b-v3-16k-q8_0"
        ]
    },
    "thepradip/mixtral2x7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "lasernav/dolphin-sophyai": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/beyonder-4x7b": {
        "description": "No description",
        "tags": [
            "latest",
            "v2",
            "v2-Q5_k_m",
            "v2-Q4_k_m"
        ]
    },
    "sparksammy/rubai": {
        "description": "an ai based on a person who hates ai. no, this is NOT based on her site. (patchmixolydic)",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.13": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.12": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.6": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chris/mixtralcpu": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jowings/pds": {
        "description": "No description",
        "tags": [
            "latest",
            "new"
        ]
    },
    "rayyildiz/symin": {
        "description": "minimalist model",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/greennode": {
        "description": "7b",
        "tags": [
            "latest"
        ]
    },
    "filipe/tulu-2-dpo": {
        "description": "No description",
        "tags": [
            "latest",
            "70b-q4_0"
        ]
    },
    "maximebodereau/hr_jems": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "kusanagi/ruby-una-cybertron-7b-v2-bf16": {
        "description": "una-cybertron-7b-v2-bf16 for writing ruby codes",
        "tags": [
            "latest"
        ]
    },
    "mangiucugna/bakllava-1": {
        "description": "Multi-modal model based on llava-1.5. Source: https://huggingface.co/mys/ggml_bakllava-1",
        "tags": [
            "latest"
        ]
    },
    "svk/docsgpt-7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/virtualdoctor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/travelguide": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/techwriter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/svgdesigner": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/startuptechlawyer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/screenwriter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/pythoninterpreter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/psychologist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/passwordgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/linuxterminal": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/legaladvisor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/languagedetector": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/journalist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/instructorinaschool": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/hypnotherapist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/classicalmusiccomposer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/academician": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "pdevine/openhermes-mistral": {
        "description": "No description",
        "tags": [
            "7b"
        ]
    },
    "bigllama/mistralv01-7b": {
        "description": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF : mistral-7b-instruct-v0.1.Q3_K_M.gguf",
        "tags": [
            "latest"
        ]
    },
    "avinish/finetuned-qunatized": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "f0rodo/rule-builder": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "zctech/zctechx": {
        "description": "AI\u5927\u6a21\u578b\u6280\u672f\u9a71\u52a8\u6570\u5b57\u5b6a\u751f+\u4ea7\u4e1a\u5e94\u7528",
        "tags": [
            "latest"
        ]
    },
    "cas/snorkel-mistral-pairrm-dpo": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "metythorn/code-phi": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chand1012/tldr_content": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "yshuang/chinese_test_template_2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "edisonzf2020d/starling-lm-7b-alpha-128k": {
        "description": "starling-lm-7b-alpha-128k",
        "tags": [
            "latest"
        ]
    },
    "suppalapati/llama27b-v1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "murtsu/marko": {
        "description": "Using the Alfred llm I created an experiment and learned it my cv. Use for fun or whatever you want.",
        "tags": [
            "latest"
        ]
    },
    "geemobeamo/dartagnon": {
        "description": "personality of Dartagnon for dialog",
        "tags": [
            "latest"
        ]
    },
    "marcelom70/modeia-assistant": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/mistral": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "sskostyaev/deepseek-math": {
        "description": "No description",
        "tags": [
            "7b-rl.Q6_K"
        ]
    },
    "terry/mistral-omniverse": {
        "description": "this model is fine-tune on Nvidia documents related to Omniverse, it helps you to answer questions about Omniverse.",
        "tags": [
            "latest"
        ]
    },
    "uyasin/example": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/minicpm-3b-hephaestus": {
        "description": "from gmonsoon/MiniCPM-3B-Hephaestus-GGUF",
        "tags": [
            "latest"
        ]
    },
    "cas/wiedervereinigung-7b-dpo-laser": {
        "description": "from mayflowergmbh/Wiedervereinigung-7b-dpo-laser-GGUF",
        "tags": [
            "latest"
        ]
    },
    "savethedoctor/whiterabbitneo13bq8_0": {
        "description": "Based off of https://huggingface.co/whiterabbitneo/WhiteRabbitNeo-13B Q8_0",
        "tags": [
            "latest"
        ]
    },
    "timpal0l/beaglecatmunin": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chriscelaya/deepseek-coder": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "yshuang/test": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tejasmankweshwar/legalsathi": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "anik/copilot_llama2": {
        "description": "Custom model for code generation based on llama2",
        "tags": [
            "latest"
        ]
    },
    "tavernari/swift-doc-generator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jackinderly/oppenheimer": {
        "description": "Talk to J. Robert Oppenheimer",
        "tags": [
            "latest"
        ]
    },
    "siegemt/legislama": {
        "description": "for legislative amendments/bill context",
        "tags": [
            "latest"
        ]
    },
    "mgmacleod/airoboros-mistral": {
        "description": "airoboros-mistral",
        "tags": [
            "latest"
        ]
    },
    "koji/dr_samantha-7b": {
        "description": "Dr. Samantha 7B Model",
        "tags": [
            "latest"
        ]
    },
    "morenod/ogthome": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/yesno": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "pdevine/nicestuff": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.16": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.14": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "smartkit/yangboz": {
        "description": "an LLM digital human for https://www.linkedin.com/in/yangbozhou/",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.11": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bitbinge/stickler": {
        "description": "A friendly coding mentor...",
        "tags": [
            "latest"
        ]
    },
    "kaladivo/chat-therapist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.9": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.8": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.7": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.5": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "breitburg/tinyllama": {
        "description": "A Llama-like 1.1B model trained on 3 trillion tokens",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-v0.3": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "omkarenator/amberchat": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/tachikoma-tf-v0.1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "spyy/x": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jaigouk/bruins-v2.1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tangotew/cheerchat5": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tangotew/cheerchat4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tangotew/cheerchat2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "josiahbryan/dragon-mistral-7b-v0-q4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "airat/karen-the-editor-v2-strict": {
        "description": "Karen is an editor for your text. (v.2) STRICT edition",
        "tags": [
            "latest"
        ]
    },
    "tangotew/cheerchat": {
        "description": "This the mood booster model tailored as a best friend.",
        "tags": [
            "latest"
        ]
    },
    "pdevine/grammarfix": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "rodneyxr/neural-chat": {
        "description": "https://huggingface.co/TheBloke/neural-chat-7B-v3-1-GGUF",
        "tags": [
            "7b-3.1"
        ]
    },
    "mazyod/dolphin2.2.1-mistral": {
        "description": "No description",
        "tags": [
            "7b"
        ]
    },
    "hemanth/titlegeneratorforwrittenpieces": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/timetravelguide": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/socialmediainfluencer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/essaywriter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/diagramgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/chessplayer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/characterfrommoviebookanything": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/asciiartist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/aiwritingtutor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "adeelahmad/aws-zephyr-7b-alpha": {
        "description": "AWS AI",
        "tags": [
            "latest"
        ]
    },
    "sethburkart123/photolens": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "rasun/speechless-llama2-hermes-orca-platypus-wizardlm": {
        "description": "No description",
        "tags": [
            "latest",
            "13b-q4",
            "13b-q4_K_M"
        ]
    },
    "suppalapati/mistral-v1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "makhat/mkollamamodel": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/brezn-7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chand1012/tldr_headline": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chand1012/drop_explained": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chand1012/drop": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "joreilly86/structural_llama": {
        "description": "Assistant for structural engineering design and analysis, with emphasis on Python code assistance. Built off llama2-13b.",
        "tags": [
            "latest"
        ]
    },
    "alenbijelic/devops": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "sammcj/smaug-mixtral-v0.1.imatrix": {
        "description": "see https://ollama.com/sammcj/smaug-mixtral-v0.1",
        "tags": [
            "70b-q4_k_m"
        ]
    },
    "geemobeamo/aramis": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "geemobeamo/porthos": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "geemobeamo/athos": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/llava": {
        "description": "No description",
        "tags": [
            "34b"
        ]
    },
    "sskostyaev/mistral": {
        "description": "No description",
        "tags": [
            "32k",
            "32k-rag",
            "7b-instruct-v0.2-q6_K-1l",
            "7b-instruct-v0.2-q6_K-32k",
            "7b-instruct-v0.2-q6_K-32k-rag"
        ]
    },
    "npien/vistral-4bit": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "macadeliccc/samantha-1.1-mbx-7b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "m/mycoolmodel": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "esantiago/emojitron": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cas/minicpm-3b-turangga-v3-ep50": {
        "description": "from gmonsoon/MiniCPM-3B-Turangga-v3-ep50-GGUF",
        "tags": [
            "latest"
        ]
    },
    "cas/minicpm-3b-openhermes-2.5-v2": {
        "description": "from sayhan/MiniCPM-3B-OpenHermes-2.5-v2-GGUF",
        "tags": [
            "latest"
        ]
    },
    "dkm/tinyllama": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "pdevine/mistral-convert": {
        "description": "No description",
        "tags": [
            "f16"
        ]
    },
    "yahiaberashish/lingual-tr": {
        "description": "A translator LLM.",
        "tags": [
            "latest"
        ]
    },
    "nqduc/mixsura-sft": {
        "description": "No description",
        "tags": [
            "latest",
            "mixsura-sft-q4_0",
            "mixsura-sft-q4_1",
            "mixsura-sft-q5_1",
            "mixsura-sft-q8_0",
            "mixsura-sft-q2_K",
            "mixsura-sft-q3_K",
            "mixsura-sft-q3_K_S",
            "mixsura-sft-q3_K_M",
            "mixsura-sft-q4_K",
            "mixsura-sft-q4_K_S",
            "mixsura-sft-q4_K_M",
            "mixsura-sft-q5_K",
            "mixsura-sft-q5_K_S",
            "mixsura-sft-q5_K_M",
            "mixsura-sft-q6_K",
            "mixsura-sft-fp16"
        ]
    },
    "nqduc/mixsura": {
        "description": "No description",
        "tags": [
            "latest",
            "mixsura-q4_0",
            "mixsura-q4_1",
            "mixsura-q5_1",
            "mixsura-q8_0",
            "mixsura-q2_K",
            "mixsura-q3_K",
            "mixsura-q3_K_S",
            "mixsura-q3_K_M",
            "mixsura-q4_K",
            "mixsura-q4_K_S",
            "mixsura-q4_K_M",
            "mixsura-q5_K",
            "mixsura-q5_K_S",
            "mixsura-q5_K_M",
            "mixsura-q6_K",
            "mixsura-fp16"
        ]
    },
    "chriscelaya/deepstack-developer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "chriscelaya/neural-mario": {
        "description": "Super Mario with Neural Chat language model",
        "tags": [
            "latest"
        ]
    },
    "yshuang/chinese_med_q4_k_s": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "yshuang/chinese_med_q4_k_m": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "tkdkid1000/phi-1_5": {
        "description": "The language model Phi-1.5 is a Transformer with 1.3 billion parameters.",
        "tags": [
            "latest",
            "chat",
            "text"
        ]
    },
    "darinpope/the-butler": {
        "description": "No description",
        "tags": [
            "latest",
            "v0.2"
        ]
    },
    "roger/emojitron": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bhargav/donkey-initial": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "smartkit/manscriptmaster": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "stardustc/elon-musk-mistral": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "nxphi47/seallm-7b-v2-q4_0": {
        "description": "State-of-the-art multilingual LLM for Southeast Asian (SEA) languages \ud83c\uddec\ud83c\udde7 \ud83c\udde8\ud83c\uddf3 \ud83c\uddfb\ud83c\uddf3 \ud83c\uddee\ud83c\udde9 \ud83c\uddf9\ud83c\udded \ud83c\uddf2\ud83c\uddfe \ud83c\uddf0\ud83c\udded \ud83c\uddf1\ud83c\udde6 \ud83c\uddf2\ud83c\uddf2 \ud83c\uddf5\ud83c\udded.",
        "tags": [
            "latest"
        ]
    },
    "verias/devia-2.0": {
        "description": "Some tinkering and prompt engineering behind an uncensored 13B dataset",
        "tags": [
            "latest"
        ]
    },
    "dujun/ragout-fc": {
        "description": "Optimization for function calling scenarios",
        "tags": [
            "latest"
        ]
    },
    "yemmiismail/mixed": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "nikoreno/rita": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "maximebodereau/personacreatormistral": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "okfth/llama2-password-classifier": {
        "description": "Password classifier",
        "tags": [
            "latest"
        ]
    },
    "thepradip/drsamantha": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgan/llama2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mingli512/ggml-model-q4_0.gguf": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mingli512/tinyllamas-stories-110m-f32.gguf": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "mingli512/tinyllamas-stories-260k-f32": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "lasernav/sophyai-work-safety": {
        "description": "No description",
        "tags": [
            "Q4_K_M"
        ]
    },
    "jmorgan/test": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "drewskidang/dirt-bag": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "aisherpa/wizardmath-7b-v1.1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "gbaptista/mario": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bitbinge/dazz": {
        "description": "A general purpose assistant",
        "tags": [
            "latest"
        ]
    },
    "bitbinge/zoar": {
        "description": "A work in progress...",
        "tags": [
            "latest"
        ]
    },
    "mattw/amazon_mistrallite": {
        "description": "No description",
        "tags": [
            "f16",
            "q4_1",
            "q5_0",
            "q5_1",
            "q8_0",
            "q2_K",
            "q3_K_S",
            "q3_K_M",
            "q3_K_L",
            "q4_K_S",
            "q4_K_M",
            "q5_K_S",
            "q5_K_M",
            "q6_K"
        ]
    },
    "mattw/hfzephyr-7b-beta": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "z0r0z/dolphin-mixtral-2.5-gguf": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "vokturz/mistral-7b-prompter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "xe/yi-chat-6b": {
        "description": "No description",
        "tags": [
            "f16"
        ]
    },
    "davidberenstein1957/notus": {
        "description": "\ud83d\udca8 Notus 7B is an open source LLM released by Argilla, fine-tuned using Direct Preference Optimization (DPO) and AIF (AI Feedback) techniques. This model is fine-tuned with a better curated version of the Ultrafeedback dataset.",
        "tags": [
            "q4_0",
            "q5_0",
            "q8_0",
            "q2_K",
            "q3_K_S",
            "q3_K_M",
            "q3_K_L",
            "q4_K_S",
            "q4_K_M",
            "q5_K_S",
            "q5_K_M",
            "q6_K"
        ]
    },
    "bhargav/donkey-soql": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "thatguyjamal/codellama": {
        "description": "Your custom code assistant",
        "tags": [
            "latest"
        ]
    },
    "kimball555/labdays": {
        "description": "Lab Days AI",
        "tags": [
            "latest"
        ]
    },
    "jsneh/incoherent": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgantesting/codellama": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "jmorgantesting/test": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bruceignoretest/bruce-test-4": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bruceignoretest/bruce-test-3": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bruceignoretest/bruce-test-2": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "bruceignoretest/bruce-test-1": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/yogi": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/webdesignconsultant": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/webbrowser": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/uxuideveloper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/unconstrainedaimodeldan": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/tictactoegame": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/textbasedadventuregame": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/techreviewer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/technologytransferer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/teataster": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/talentcoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/synonymfinder": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/statistician": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/startupideagenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/standupcomedian": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/stackoverflowpost": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/sqlterminal": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/spongebobsmagicconchshell": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/speechlanguagepathologistslp": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/songrecommender": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/solrsearchengine": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/softwarequalityassurancetester": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/socraticmethod": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/socrat": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/socialmediamanager": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/smartdomainnamegenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/seniorfrontenddeveloper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/selfhelpbook": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/salesperson": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/rprogramminginterpreter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/relationshipcoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/regexgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/recruiter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/realestateagent": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/rapper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/publicspeakingcoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/proofreader": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/promptgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/productmanager": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/poet": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/plagiarismchecker": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/philosophyteacher": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/petbehaviorist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/personaltrainer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/personalstylist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/personalshopper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/personalchef": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/newlanguagecreator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/muslimimam": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/moviecritic": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/motivationalspeaker": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/motivationalcoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/mentalhealthadviser": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/mathteacher": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/mathematician": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/mathematicalhistoryteacher": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/makeupartist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/magician": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/machinelearningengineer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/lunatic": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/logistician": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/lifecoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/journalreviewer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/javascriptconsole": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/itexpert": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/itarchitect": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/investmentmanager": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/interiordecorator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/historian": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/gomokuplayer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/gnomist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/gaslighter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/fullstacksoftwaredeveloper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/footballcommentator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/foodcritic": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/florist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/filmcritic": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/fillintheblankworksheetsgenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/fancytitlegenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/fallacyfinder": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/excelsheet": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/etymologist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/englishpronunciationhelper": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/emojitranslator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/emergencyresponseprofessional": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/elocutionist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/educationalcontentcreator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/dreaminterpreter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/diyexpert": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/digitalartgalleryguide": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/dietitian": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/developerrelationsconsultant": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/dentist": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/debater": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/debatecoach": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/coverletter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/composer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/commitmessagegenerator": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/commentariat": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/chiefexecutiveofficer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/chef": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/carnavigationsystem": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/careercounselor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/babysitter": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/automobilemechanic": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/astrologer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/artistadvisor": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/aphorismbook": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/aitryingtoescapethebox": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/advertiser": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "hemanth/positioninterviewer": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "eas/free_sydney_v2_13b": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    },
    "cloudmidleman/codeitlab": {
        "description": "the fastest coder around!",
        "tags": [
            "latest"
        ]
    },
    "f0rodo/encore": {
        "description": "No description",
        "tags": [
            "latest"
        ]
    }
}
